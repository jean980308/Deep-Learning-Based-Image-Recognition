{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "efficientnet_Lite.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-d9QvIKvDD8"
      },
      "outputs": [],
      "source": [
        "# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CFAR-10"
      ],
      "metadata": {
        "id": "BrBdsOJgi07v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-Y_BFDasDw9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset     = torchvision.datasets.CIFAR10(root='./data' ,train=True,download=True,transform=transform)\n",
        "\n",
        "trainloader   = torch.utils.data.DataLoader(trainset , batch_size=batch_size,shuffle=True , num_workers=2)\n",
        "\n",
        "testset     = torchvision.datasets.CIFAR10(root='./data' ,train=True,download=True , transform=transform)\n",
        "\n",
        "testloader =torch.utils.data.DataLoader(testset , batch_size=batch_size ,shuffle=False ,num_workers=2)\n",
        "\n",
        "classes = ('plane' , 'car' ,'bird' , 'cat' , 'deer' ,'dog' ,'frog' ,'horse' ,'ship' , 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aWA3UdDtlGty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    img= img/2 +0.5\n",
        "    npimg=img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "    plt.show()\n",
        "    \n",
        "dataiter= iter(trainloader)\n",
        "images , labels =dataiter.next()\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "print(''.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n"
      ],
      "metadata": {
        "id": "taK-RIEYsieo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lars_optimizer"
      ],
      "metadata": {
        "id": "_lT6FSupi_nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Layer-wise Adaptive Rate Scaling optimizer for large-batch training.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "\n",
        "class LARSOptimizer(tf.train.Optimizer):\n",
        "  \"\"\"Layer-wise Adaptive Rate Scaling for large batch training.\n",
        "  Introduced by \"Large Batch Training of Convolutional Networks\" by Y. You,\n",
        "  I. Gitman, and B. Ginsburg. (https://arxiv.org/abs/1708.03888)\n",
        "  Implements the LARS learning rate scheme presented in the paper above. This\n",
        "  optimizer is useful when scaling the batch size to up to 32K without\n",
        "  significant performance degradation. It is recommended to use the optimizer\n",
        "  in conjunction with:\n",
        "      - Gradual learning rate warm-up\n",
        "      - Linear learning rate scaling\n",
        "      - Poly rule learning rate decay\n",
        "  Note, LARS scaling is currently only enabled for dense tensors. Sparse tensors\n",
        "  use the default momentum optimizer.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      learning_rate,\n",
        "      momentum=0.9,\n",
        "      weight_decay=0.0001,\n",
        "      # The LARS coefficient is a hyperparameter\n",
        "      eeta=0.001,\n",
        "      epsilon=0.0,\n",
        "      name=\"LARSOptimizer\",\n",
        "      # Enable skipping variables from LARS scaling.\n",
        "      # TODO(sameerkm): Enable a direct mechanism to pass a\n",
        "      # subset of variables to the optimizer.\n",
        "      skip_list=None,\n",
        "      use_nesterov=False):\n",
        "    \"\"\"Construct a new LARS Optimizer.\n",
        "    Args:\n",
        "      learning_rate: A `Tensor` or floating point value. The base learning rate.\n",
        "      momentum: A floating point value. Momentum hyperparameter.\n",
        "      weight_decay: A floating point value. Weight decay hyperparameter.\n",
        "      eeta: LARS coefficient as used in the paper. Dfault set to LARS\n",
        "        coefficient from the paper. (eeta / weight_decay) determines the highest\n",
        "        scaling factor in LARS.\n",
        "      epsilon: Optional epsilon parameter to be set in models that have very\n",
        "        small gradients. Default set to 0.0.\n",
        "      name: Optional name prefix for variables and ops created by LARSOptimizer.\n",
        "      skip_list: List of strings to enable skipping variables from LARS scaling.\n",
        "        If any of the strings in skip_list is a subset of var.name, variable\n",
        "        'var' is skipped from LARS scaling. For a typical classification model\n",
        "        with batch normalization, the skip_list is ['batch_normalization',\n",
        "        'bias']\n",
        "      use_nesterov: when set to True, nesterov momentum will be enabled\n",
        "    Raises:\n",
        "      ValueError: If a hyperparameter is set to a non-sensical value.\n",
        "    \"\"\"\n",
        "    if momentum < 0.0:\n",
        "      raise ValueError(\"momentum should be positive: %s\" % momentum)\n",
        "    if weight_decay < 0.0:\n",
        "      raise ValueError(\"weight_decay should be positive: %s\" % weight_decay)\n",
        "    super(LARSOptimizer, self).__init__(use_locking=False, name=name)\n",
        "\n",
        "    self._learning_rate = learning_rate\n",
        "    self._momentum = momentum\n",
        "    self._weight_decay = weight_decay\n",
        "    self._eeta = eeta\n",
        "    self._epsilon = epsilon\n",
        "    self._name = name\n",
        "    self._skip_list = skip_list\n",
        "    self._use_nesterov = use_nesterov\n",
        "\n",
        "  def _create_slots(self, var_list):\n",
        "    for v in var_list:\n",
        "      self._zeros_slot(v, \"momentum\", self._name)\n",
        "\n",
        "  def compute_lr(self, grad, var):\n",
        "    scaled_lr = self._learning_rate\n",
        "    if self._skip_list is None or not any(v in var.name\n",
        "                                          for v in self._skip_list):\n",
        "      w_norm = tf.norm(var, ord=2)\n",
        "      g_norm = tf.norm(grad, ord=2)\n",
        "      trust_ratio = tf.where(\n",
        "          tf.math.greater(w_norm, 0),\n",
        "          tf.where(\n",
        "              tf.math.greater(g_norm, 0),\n",
        "              (self._eeta * w_norm /\n",
        "               (g_norm + self._weight_decay * w_norm + self._epsilon)), 1.0),\n",
        "          1.0)\n",
        "      scaled_lr = self._learning_rate * trust_ratio\n",
        "      # Add the weight regularization gradient\n",
        "      grad = grad + self._weight_decay * var\n",
        "    return scaled_lr, grad\n",
        "\n",
        "  def _apply_dense(self, grad, var):\n",
        "    scaled_lr, grad = self.compute_lr(grad, var)\n",
        "    mom = self.get_slot(var, \"momentum\")\n",
        "    return tf.raw_ops.ApplyMomentum(\n",
        "        var,\n",
        "        mom,\n",
        "        tf.cast(1.0, var.dtype.base_dtype),\n",
        "        grad * scaled_lr,\n",
        "        self._momentum,\n",
        "        use_locking=False,\n",
        "        use_nesterov=self._use_nesterov)\n",
        "\n",
        "  def _resource_apply_dense(self, grad, var):\n",
        "    scaled_lr, grad = self.compute_lr(grad, var)\n",
        "    mom = self.get_slot(var, \"momentum\")\n",
        "    return tf.raw_ops.ResourceApplyMomentum(\n",
        "        var=var.handle,\n",
        "        accum=mom.handle,\n",
        "        lr=tf.cast(1.0, var.dtype.base_dtype),\n",
        "        grad=grad * scaled_lr,\n",
        "        momentum=self._momentum,\n",
        "        use_locking=False,\n",
        "        use_nesterov=self._use_nesterov)\n",
        "\n",
        "  # Fallback to momentum optimizer for sparse tensors\n",
        "  def _apply_sparse(self, grad, var):\n",
        "    mom = self.get_slot(var, \"momentum\")\n",
        "    return tf.raw_ops.SparseApplyMomentum(\n",
        "        var,\n",
        "        mom,\n",
        "        tf.cast(self._learning_rate_tensor, var.dtype.base_dtype),\n",
        "        grad.values,\n",
        "        grad.indices,\n",
        "        tf.cast(self._momentum_tensor, var.dtype.base_dtype),\n",
        "        use_locking=self._use_locking,\n",
        "        use_nesterov=self._use_nesterov).op\n",
        "\n",
        "  def _resource_apply_sparse(self, grad, var, indices):\n",
        "    mom = self.get_slot(var, \"momentum\")\n",
        "    return tf.raw_ops.ResourceSparseApplyMomentum(\n",
        "        var.handle,\n",
        "        mom.handle,\n",
        "        tf.cast(self._learning_rate_tensor, grad.dtype),\n",
        "        grad,\n",
        "        indices,\n",
        "        tf.cast(self._momentum_tensor, grad.dtype),\n",
        "        use_locking=self._use_locking,\n",
        "        use_nesterov=self._use_nesterov)\n",
        "\n",
        "  def _prepare(self):\n",
        "    learning_rate = self._learning_rate\n",
        "    if callable(learning_rate):\n",
        "      learning_rate = learning_rate()\n",
        "    self._learning_rate_tensor = tf.convert_to_tensor(\n",
        "        learning_rate, name=\"learning_rate\")\n",
        "    momentum = self._momentum\n",
        "    if callable(momentum):\n",
        "      momentum = momentum()\n",
        "    self._momentum_tensor = tf.convert_to_tensor(momentum, name=\"momentum\")"
      ],
      "metadata": {
        "id": "dhzGpkV-l0dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils.py "
      ],
      "metadata": {
        "id": "W7z2Y7F8jDQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Model utilities.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from absl import flags\n",
        "from absl import logging\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "#import lars_optimizer\n",
        "from tensorflow.python.tpu import tpu_function  # pylint:disable=g-direct-tensorflow-import\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def build_learning_rate(initial_lr,\n",
        "                        global_step,\n",
        "                        steps_per_epoch=None,\n",
        "                        lr_decay_type='exponential',\n",
        "                        decay_factor=0.97,\n",
        "                        decay_epochs=2.4,\n",
        "                        total_steps=None,\n",
        "                        warmup_epochs=5):\n",
        "  \"\"\"Build learning rate.\"\"\"\n",
        "  if lr_decay_type == 'exponential':\n",
        "    assert steps_per_epoch is not None\n",
        "    decay_steps = steps_per_epoch * decay_epochs\n",
        "    lr = tf.train.exponential_decay(\n",
        "        initial_lr, global_step, decay_steps, decay_factor, staircase=True)\n",
        "  elif lr_decay_type == 'cosine':\n",
        "    assert total_steps is not None\n",
        "    lr = 0.5 * initial_lr * (\n",
        "        1 + tf.cos(np.pi * tf.cast(global_step, tf.float32) / total_steps))\n",
        "  elif lr_decay_type == 'constant':\n",
        "    lr = initial_lr\n",
        "  elif lr_decay_type == 'poly':\n",
        "    tf.logging.info('Using poly LR schedule')\n",
        "    assert steps_per_epoch is not None\n",
        "    assert total_steps is not None\n",
        "    warmup_steps = int(steps_per_epoch * warmup_epochs)\n",
        "    min_step = tf.constant(1, dtype=tf.int64)\n",
        "    decay_steps = tf.maximum(min_step, tf.subtract(global_step, warmup_steps))\n",
        "    lr = tf.train.polynomial_decay(\n",
        "        initial_lr,\n",
        "        decay_steps,\n",
        "        total_steps - warmup_steps + 1,\n",
        "        end_learning_rate=0.1,\n",
        "        power=2.0)\n",
        "  else:\n",
        "    assert False, 'Unknown lr_decay_type : %s' % lr_decay_type\n",
        "\n",
        "  if warmup_epochs:\n",
        "    logging.info('Learning rate warmup_epochs: %d', warmup_epochs)\n",
        "    warmup_steps = int(warmup_epochs * steps_per_epoch)\n",
        "    warmup_lr = (\n",
        "        initial_lr * tf.cast(global_step, tf.float32) / tf.cast(\n",
        "            warmup_steps, tf.float32))\n",
        "    lr = tf.cond(global_step < warmup_steps, lambda: warmup_lr, lambda: lr)\n",
        "\n",
        "  return lr\n",
        "\n",
        "\n",
        "def build_optimizer(learning_rate,\n",
        "                    optimizer_name='rmsprop',\n",
        "                    decay=0.9,\n",
        "                    epsilon=0.001,\n",
        "                    momentum=0.9,\n",
        "                    lars_weight_decay=None,\n",
        "                    lars_epsilon=None):\n",
        "  \"\"\"Build optimizer.\"\"\"\n",
        "  if optimizer_name == 'sgd':\n",
        "    logging.info('Using SGD optimizer')\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  elif optimizer_name == 'momentum':\n",
        "    logging.info('Using Momentum optimizer')\n",
        "    optimizer = tf.train.MomentumOptimizer(\n",
        "        learning_rate=learning_rate, momentum=momentum)\n",
        "  elif optimizer_name == 'rmsprop':\n",
        "    logging.info('Using RMSProp optimizer')\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate, decay, momentum,\n",
        "                                          epsilon)\n",
        "  elif optimizer_name == 'lars':\n",
        "    logging.info('Using LARS optimizer')\n",
        "    assert lars_weight_decay is not None, 'LARS weight decay is None.'\n",
        "    assert lars_epsilon is not None, 'LARS epsilon is None.'\n",
        "    optimizer = lars_optimizer.LARSOptimizer(\n",
        "        learning_rate,\n",
        "        momentum=momentum,\n",
        "        weight_decay=lars_weight_decay,\n",
        "        skip_list=['batch_normalization', 'bias', 'beta', 'gamma'],\n",
        "        epsilon=lars_epsilon)\n",
        "  else:\n",
        "    logging.fatal('Unknown optimizer: %s', optimizer_name)\n",
        "\n",
        "  return optimizer\n",
        "\n",
        "\n",
        "class TpuBatchNormalization(tf.layers.BatchNormalization):\n",
        "  # class TpuBatchNormalization(tf.layers.BatchNormalization):\n",
        "  \"\"\"Cross replica batch normalization.\"\"\"\n",
        "\n",
        "  def __init__(self, fused=False, **kwargs):\n",
        "    if fused in (True, None):\n",
        "      raise ValueError('TpuBatchNormalization does not support fused=True.')\n",
        "    super(TpuBatchNormalization, self).__init__(fused=fused, **kwargs)\n",
        "\n",
        "  def _cross_replica_average(self, t, num_shards_per_group):\n",
        "    \"\"\"Calculates the average value of input tensor across TPU replicas.\"\"\"\n",
        "    num_shards = tpu_function.get_tpu_context().number_of_shards\n",
        "    group_assignment = None\n",
        "    if num_shards_per_group > 1:\n",
        "      if num_shards % num_shards_per_group != 0:\n",
        "        raise ValueError('num_shards: %d mod shards_per_group: %d, should be 0'\n",
        "                         % (num_shards, num_shards_per_group))\n",
        "      num_groups = num_shards // num_shards_per_group\n",
        "      group_assignment = [[\n",
        "          x for x in range(num_shards) if x // num_shards_per_group == y\n",
        "      ] for y in range(num_groups)]\n",
        "    return tf.tpu.cross_replica_sum(t, group_assignment) / tf.cast(\n",
        "        num_shards_per_group, t.dtype)\n",
        "\n",
        "  def _moments(self, inputs, reduction_axes, keep_dims):\n",
        "    \"\"\"Compute the mean and variance: it overrides the original _moments.\"\"\"\n",
        "    shard_mean, shard_variance = super(TpuBatchNormalization, self)._moments(\n",
        "        inputs, reduction_axes, keep_dims=keep_dims)\n",
        "\n",
        "    num_shards = tpu_function.get_tpu_context().number_of_shards or 1\n",
        "    if num_shards <= 8:  # Skip cross_replica for 2x2 or smaller slices.\n",
        "      num_shards_per_group = 1\n",
        "    else:\n",
        "      num_shards_per_group = max(8, num_shards // 8)\n",
        "    logging.info('TpuBatchNormalization with num_shards_per_group %s',\n",
        "                 num_shards_per_group)\n",
        "    if num_shards_per_group > 1:\n",
        "      # Compute variance using: Var[X]= E[X^2] - E[X]^2.\n",
        "      shard_square_of_mean = tf.math.square(shard_mean)\n",
        "      shard_mean_of_square = shard_variance + shard_square_of_mean\n",
        "      group_mean = self._cross_replica_average(\n",
        "          shard_mean, num_shards_per_group)\n",
        "      group_mean_of_square = self._cross_replica_average(\n",
        "          shard_mean_of_square, num_shards_per_group)\n",
        "      group_variance = group_mean_of_square - tf.math.square(group_mean)\n",
        "      return (group_mean, group_variance)\n",
        "    else:\n",
        "      return (shard_mean, shard_variance)\n",
        "\n",
        "\n",
        "class BatchNormalization(tf.layers.BatchNormalization):\n",
        "  \"\"\"Fixed default name of BatchNormalization to match TpuBatchNormalization.\"\"\"\n",
        "\n",
        "  def __init__(self, name='tpu_batch_normalization', **kwargs):\n",
        "    super(BatchNormalization, self).__init__(name=name, **kwargs)\n",
        "\n",
        "\n",
        "def train_batch_norm(**kwargs):\n",
        "  if 'optimizer' in FLAGS and FLAGS.optimizer == 'lars':\n",
        "    return DistributedBatchNormalization(**kwargs)\n",
        "  return TpuBatchNormalization(**kwargs)\n",
        "\n",
        "\n",
        "def eval_batch_norm(**kwargs):\n",
        "  if 'optimizer' in FLAGS and FLAGS.optimizer == 'lars':\n",
        "    return DistributedBatchNormalization(**kwargs)\n",
        "  return BatchNormalization(**kwargs)\n",
        "\n",
        "\n",
        "class DistributedBatchNormalization:\n",
        "  \"\"\"Distributed batch normalization used in https://arxiv.org/abs/2011.00071.\"\"\"\n",
        "\n",
        "  def __init__(self, axis, momentum, epsilon):\n",
        "    self.axis = axis\n",
        "    self.momentum = momentum\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def __call__(self, x, training, distname='batch_normalization'):\n",
        "    shape = [x.shape[-1]]\n",
        "    with tf.variable_scope('batch_normalization'):\n",
        "      ones = tf.initializers.ones()\n",
        "      zeros = tf.initializers.zeros()\n",
        "      gamma = tf.get_variable(\n",
        "          'gamma', shape, initializer=ones, trainable=True, use_resource=True)\n",
        "      beta = tf.get_variable(\n",
        "          'beta', shape, initializer=zeros, trainable=True, use_resource=True)\n",
        "      moving_mean = tf.get_variable(\n",
        "          'moving_mean',\n",
        "          shape,\n",
        "          initializer=zeros,\n",
        "          trainable=False,\n",
        "          use_resource=True)\n",
        "      moving_variance = tf.get_variable(\n",
        "          'moving_variance',\n",
        "          shape,\n",
        "          initializer=ones,\n",
        "          trainable=False,\n",
        "          use_resource=True)\n",
        "    num_replicas = FLAGS.num_replicas\n",
        "\n",
        "    x = tf.cast(x, tf.float32)\n",
        "    if training:\n",
        "      if num_replicas <= 8:\n",
        "        group_assign = None\n",
        "        group_shards = tf.cast(num_replicas, tf.float32)\n",
        "      else:\n",
        "\n",
        "        group_shards = max(\n",
        "            1,\n",
        "            int(FLAGS.batch_norm_batch_size /\n",
        "                (FLAGS.train_batch_size / num_replicas)))\n",
        "        group_assign = np.arange(num_replicas, dtype=np.int32)\n",
        "        group_assign = group_assign.reshape([-1, group_shards])\n",
        "        group_assign = group_assign.tolist()\n",
        "        group_shards = tf.cast(group_shards, tf.float32)\n",
        "\n",
        "      mean = tf.reduce_mean(x, [0, 1, 2])\n",
        "      mean = tf.tpu.cross_replica_sum(mean, group_assign) / group_shards\n",
        "\n",
        "      # Var[x] = E[x^2] - E[x]^2\n",
        "      mean_sq = tf.reduce_mean(tf.math.square(x), [0, 1, 2])\n",
        "      mean_sq = tf.tpu.cross_replica_sum(mean_sq, group_assign) / group_shards\n",
        "      variance = mean_sq - tf.math.square(mean)\n",
        "\n",
        "      decay = tf.cast(1. - self.momentum, tf.float32)\n",
        "\n",
        "      def u(moving, normal, name):\n",
        "        num_replicas_fp = tf.cast(num_replicas, tf.float32)\n",
        "        normal = tf.tpu.cross_replica_sum(normal) / num_replicas_fp\n",
        "        diff = decay * (moving - normal)\n",
        "        return tf.assign_sub(moving, diff, use_locking=True, name=name)\n",
        "\n",
        "      tf.add_to_collection(tf.GraphKeys.UPDATE_OPS,\n",
        "                           u(moving_mean, mean, name='moving_mean'))\n",
        "      tf.add_to_collection(tf.GraphKeys.UPDATE_OPS,\n",
        "                           u(moving_variance, variance, name='moving_variance'))\n",
        "\n",
        "      x = tf.nn.batch_normalization(\n",
        "          x,\n",
        "          mean=mean,\n",
        "          variance=variance,\n",
        "          offset=beta,\n",
        "          scale=gamma,\n",
        "          variance_epsilon=self.epsilon)\n",
        "    else:\n",
        "\n",
        "      x, _, _ = tf.nn.fused_batch_norm(\n",
        "          x,\n",
        "          scale=gamma,\n",
        "          offset=beta,\n",
        "          mean=moving_mean,\n",
        "          variance=moving_variance,\n",
        "          epsilon=self.epsilon,\n",
        "          is_training=False)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def drop_connect(inputs, is_training, survival_prob):\n",
        "  \"\"\"Drop the entire conv with given survival probability.\"\"\"\n",
        "  # \"Deep Networks with Stochastic Depth\", https://arxiv.org/pdf/1603.09382.pdf\n",
        "  if not is_training:\n",
        "    return inputs\n",
        "\n",
        "  # Compute tensor.\n",
        "  batch_size = tf.shape(inputs)[0]\n",
        "  random_tensor = survival_prob\n",
        "  random_tensor += tf.random_uniform([batch_size, 1, 1, 1], dtype=inputs.dtype)\n",
        "  binary_tensor = tf.floor(random_tensor)\n",
        "  # Unlike conventional way that multiply survival_prob at test time, here we\n",
        "  # divide survival_prob at training time, such that no addition compute is\n",
        "  # needed at test time.\n",
        "  output = tf.div(inputs, survival_prob) * binary_tensor\n",
        "  return output\n",
        "\n",
        "\n",
        "def archive_ckpt(ckpt_eval, ckpt_objective, ckpt_path):\n",
        "  \"\"\"Archive a checkpoint if the metric is better.\"\"\"\n",
        "  ckpt_dir, ckpt_name = os.path.split(ckpt_path)\n",
        "\n",
        "  saved_objective_path = os.path.join(ckpt_dir, 'best_objective.txt')\n",
        "  saved_objective = float('-inf')\n",
        "  if tf.gfile.Exists(saved_objective_path):\n",
        "    with tf.gfile.GFile(saved_objective_path, 'r') as f:\n",
        "      saved_objective = float(f.read())\n",
        "  if saved_objective > ckpt_objective:\n",
        "    logging.info('Ckpt %s is worse than %s', ckpt_objective, saved_objective)\n",
        "    return False\n",
        "\n",
        "  filenames = tf.gfile.Glob(ckpt_path + '.*')\n",
        "  if filenames is None:\n",
        "    logging.info('No files to copy for checkpoint %s', ckpt_path)\n",
        "    return False\n",
        "\n",
        "  # Clear the old folder.\n",
        "  dst_dir = os.path.join(ckpt_dir, 'archive')\n",
        "  if tf.gfile.Exists(dst_dir):\n",
        "    tf.gfile.DeleteRecursively(dst_dir)\n",
        "  tf.gfile.MakeDirs(dst_dir)\n",
        "\n",
        "  # Write checkpoints.\n",
        "  for f in filenames:\n",
        "    dest = os.path.join(dst_dir, os.path.basename(f))\n",
        "    tf.gfile.Copy(f, dest, overwrite=True)\n",
        "  ckpt_state = tf.train.generate_checkpoint_state_proto(\n",
        "      dst_dir,\n",
        "      model_checkpoint_path=ckpt_name,\n",
        "      all_model_checkpoint_paths=[ckpt_name])\n",
        "  with tf.gfile.GFile(os.path.join(dst_dir, 'checkpoint'), 'w') as f:\n",
        "    f.write(str(ckpt_state))\n",
        "  with tf.gfile.GFile(os.path.join(dst_dir, 'best_eval.txt'), 'w') as f:\n",
        "    f.write('%s' % ckpt_eval)\n",
        "\n",
        "  # Update the best objective.\n",
        "  with tf.gfile.GFile(saved_objective_path, 'w') as f:\n",
        "    f.write('%f' % ckpt_objective)\n",
        "\n",
        "  logging.info('Copying checkpoint %s to %s', ckpt_path, dst_dir)\n",
        "  return True\n",
        "\n",
        "\n",
        "def get_ema_vars():\n",
        "  \"\"\"Get all exponential moving average (ema) variables.\"\"\"\n",
        "  ema_vars = tf.trainable_variables() + tf.get_collection('moving_vars')\n",
        "  for v in tf.global_variables():\n",
        "    # We maintain mva for batch norm moving mean and variance as well.\n",
        "    if 'moving_mean' in v.name or 'moving_variance' in v.name:\n",
        "      ema_vars.append(v)\n",
        "  return list(set(ema_vars))\n",
        "\n",
        "\n",
        "class DepthwiseConv2D(tf.keras.layers.DepthwiseConv2D, tf.layers.Layer):\n",
        "  \"\"\"Wrap keras DepthwiseConv2D to tf.layers.\"\"\"\n",
        "\n",
        "  pass\n",
        "\n",
        "\n",
        "class Conv2D(tf.layers.Conv2D):\n",
        "  \"\"\"Wrapper for Conv2D with specialization for fast inference.\"\"\"\n",
        "\n",
        "  def _bias_activation(self, outputs):\n",
        "    if self.use_bias:\n",
        "      outputs = tf.nn.bias_add(outputs, self.bias, data_format='NCHW')\n",
        "    if self.activation is not None:\n",
        "      return self.activation(outputs)\n",
        "    return outputs\n",
        "\n",
        "  def _can_run_fast_1x1(self, inputs):\n",
        "    batch_size = inputs.shape.as_list()[0]\n",
        "    return (self.data_format == 'channels_first' and\n",
        "            batch_size == 1 and\n",
        "            self.kernel_size == (1, 1))\n",
        "\n",
        "  def _call_fast_1x1(self, inputs):\n",
        "    # Compute the 1x1 convolution as a matmul.\n",
        "    inputs_shape = tf.shape(inputs)\n",
        "    flat_inputs = tf.reshape(inputs, [inputs_shape[1], -1])\n",
        "    flat_outputs = tf.matmul(\n",
        "        tf.squeeze(self.kernel),\n",
        "        flat_inputs,\n",
        "        transpose_a=True)\n",
        "    outputs_shape = tf.concat([[1, self.filters], inputs_shape[2:]], axis=0)\n",
        "    outputs = tf.reshape(flat_outputs, outputs_shape)\n",
        "\n",
        "    # Handle the bias and activation function.\n",
        "    return self._bias_activation(outputs)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if self._can_run_fast_1x1(inputs):\n",
        "      return self._call_fast_1x1(inputs)\n",
        "    return super(Conv2D, self).call(inputs)\n",
        "\n",
        "\n",
        "class EvalCkptDriver(object):\n",
        "  \"\"\"A driver for running eval inference.\n",
        "  Attributes:\n",
        "    model_name: str. Model name to eval.\n",
        "    batch_size: int. Eval batch size.\n",
        "    image_size: int. Input image size, determined by model name.\n",
        "    num_classes: int. Number of classes, default to 1000 for ImageNet.\n",
        "    include_background_label: whether to include extra background label.\n",
        "    advprop_preprocessing: whether to use advprop preprocessing.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               model_name,\n",
        "               batch_size=1,\n",
        "               image_size=224,\n",
        "               num_classes=1000,\n",
        "               include_background_label=False,\n",
        "               advprop_preprocessing=False):\n",
        "    \"\"\"Initialize internal variables.\"\"\"\n",
        "    self.model_name = model_name\n",
        "    self.batch_size = batch_size\n",
        "    self.num_classes = num_classes\n",
        "    self.include_background_label = include_background_label\n",
        "    self.image_size = image_size\n",
        "    self.advprop_preprocessing = advprop_preprocessing\n",
        "\n",
        "  def restore_model(self, sess, ckpt_dir, enable_ema=True, export_ckpt=None):\n",
        "    \"\"\"Restore variables from checkpoint dir.\"\"\"\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    checkpoint = tf.train.latest_checkpoint(ckpt_dir)\n",
        "    if enable_ema:\n",
        "      ema = tf.train.ExponentialMovingAverage(decay=0.0)\n",
        "      ema_vars = get_ema_vars()\n",
        "      var_dict = ema.variables_to_restore(ema_vars)\n",
        "      ema_assign_op = ema.apply(ema_vars)\n",
        "    else:\n",
        "      var_dict = get_ema_vars()\n",
        "      ema_assign_op = None\n",
        "\n",
        "    tf.train.get_or_create_global_step()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    saver = tf.train.Saver(var_dict, max_to_keep=1)\n",
        "    saver.restore(sess, checkpoint)\n",
        "\n",
        "    if export_ckpt:\n",
        "      if ema_assign_op is not None:\n",
        "        sess.run(ema_assign_op)\n",
        "      saver = tf.train.Saver(max_to_keep=1, save_relative_paths=True)\n",
        "      saver.save(sess, export_ckpt)\n",
        "\n",
        "  def build_model(self, features, is_training):\n",
        "    \"\"\"Build model with input features.\"\"\"\n",
        "    del features, is_training\n",
        "    raise ValueError('Must be implemented by subclasses.')\n",
        "\n",
        "  def get_preprocess_fn(self):\n",
        "    raise ValueError('Must be implemented by subclsses.')\n",
        "\n",
        "  def build_dataset(self, filenames, labels, is_training):\n",
        "    \"\"\"Build input dataset.\"\"\"\n",
        "    batch_drop_remainder = False\n",
        "    if 'condconv' in self.model_name and not is_training:\n",
        "      # CondConv layers can only be called with known batch dimension. Thus, we\n",
        "      # must drop all remaining examples that do not make up one full batch.\n",
        "      # To ensure all examples are evaluated, use a batch size that evenly\n",
        "      # divides the number of files.\n",
        "      batch_drop_remainder = True\n",
        "      num_files = len(filenames)\n",
        "      if num_files % self.batch_size != 0:\n",
        "        tf.logging.warn('Remaining examples in last batch are not being '\n",
        "                        'evaluated.')\n",
        "    filenames = tf.constant(filenames)\n",
        "    labels = tf.constant(labels)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "\n",
        "    def _parse_function(filename, label):\n",
        "      image_string = tf.read_file(filename)\n",
        "      preprocess_fn = self.get_preprocess_fn()\n",
        "      image_decoded = preprocess_fn(\n",
        "          image_string, is_training, image_size=self.image_size)\n",
        "      image = tf.cast(image_decoded, tf.float32)\n",
        "      return image, label\n",
        "\n",
        "    dataset = dataset.map(_parse_function)\n",
        "    dataset = dataset.batch(self.batch_size,\n",
        "                            drop_remainder=batch_drop_remainder)\n",
        "\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    images, labels = iterator.get_next()\n",
        "    return images, labels\n",
        "\n",
        "  def run_inference(self,\n",
        "                    ckpt_dir,\n",
        "                    image_files,\n",
        "                    labels,\n",
        "                    enable_ema=True,\n",
        "                    export_ckpt=None):\n",
        "    \"\"\"Build and run inference on the target images and labels.\"\"\"\n",
        "    label_offset = 1 if self.include_background_label else 0\n",
        "    with tf.Graph().as_default(), tf.Session() as sess:\n",
        "      images, labels = self.build_dataset(image_files, labels, False)\n",
        "      probs = self.build_model(images, is_training=False)\n",
        "      if isinstance(probs, tuple):\n",
        "        probs = probs[0]\n",
        "\n",
        "      self.restore_model(sess, ckpt_dir, enable_ema, export_ckpt)\n",
        "\n",
        "      prediction_idx = []\n",
        "      prediction_prob = []\n",
        "      for _ in range(len(image_files) // self.batch_size):\n",
        "        out_probs = sess.run(probs)\n",
        "        idx = np.argsort(out_probs)[::-1]\n",
        "        prediction_idx.append(idx[:5] - label_offset)\n",
        "        prediction_prob.append([out_probs[pid] for pid in idx[:5]])\n",
        "\n",
        "      # Return the top 5 predictions (idx and prob) for each image.\n",
        "      return prediction_idx, prediction_prob\n",
        "\n",
        "  def eval_example_images(self,\n",
        "                          ckpt_dir,\n",
        "                          image_files,\n",
        "                          labels_map_file,\n",
        "                          enable_ema=True,\n",
        "                          export_ckpt=None):\n",
        "    \"\"\"Eval a list of example images.\n",
        "    Args:\n",
        "      ckpt_dir: str. Checkpoint directory path.\n",
        "      image_files: List[str]. A list of image file paths.\n",
        "      labels_map_file: str. The labels map file path.\n",
        "      enable_ema: enable expotential moving average.\n",
        "      export_ckpt: export ckpt folder.\n",
        "    Returns:\n",
        "      A tuple (pred_idx, and pred_prob), where pred_idx is the top 5 prediction\n",
        "      index and pred_prob is the top 5 prediction probability.\n",
        "    \"\"\"\n",
        "    classes = json.loads(tf.gfile.Open(labels_map_file).read())\n",
        "    pred_idx, pred_prob = self.run_inference(\n",
        "        ckpt_dir, image_files, [0] * len(image_files), enable_ema, export_ckpt)\n",
        "    for i in range(len(image_files)):\n",
        "      print('predicted class for image {}: '.format(image_files[i]))\n",
        "      for j, idx in enumerate(pred_idx[i]):\n",
        "        print('  -> top_{} ({:4.2f}%): {}  '.format(j, pred_prob[i][j] * 100,\n",
        "                                                    classes[str(idx)]))\n",
        "    return pred_idx, pred_prob\n",
        "\n",
        "  def eval_imagenet(self, ckpt_dir, imagenet_eval_glob,\n",
        "                    imagenet_eval_label, num_images, enable_ema, export_ckpt):\n",
        "    \"\"\"Eval ImageNet images and report top1/top5 accuracy.\n",
        "    Args:\n",
        "      ckpt_dir: str. Checkpoint directory path.\n",
        "      imagenet_eval_glob: str. File path glob for all eval images.\n",
        "      imagenet_eval_label: str. File path for eval label.\n",
        "      num_images: int. Number of images to eval: -1 means eval the whole\n",
        "        dataset.\n",
        "      enable_ema: enable expotential moving average.\n",
        "      export_ckpt: export checkpoint folder.\n",
        "    Returns:\n",
        "      A tuple (top1, top5) for top1 and top5 accuracy.\n",
        "    \"\"\"\n",
        "    imagenet_val_labels = [int(i) for i in tf.gfile.GFile(imagenet_eval_label)]\n",
        "    imagenet_filenames = sorted(tf.gfile.Glob(imagenet_eval_glob))\n",
        "    if num_images < 0:\n",
        "      num_images = len(imagenet_filenames)\n",
        "    image_files = imagenet_filenames[:num_images]\n",
        "    labels = imagenet_val_labels[:num_images]\n",
        "\n",
        "    pred_idx, _ = self.run_inference(\n",
        "        ckpt_dir, image_files, labels, enable_ema, export_ckpt)\n",
        "    top1_cnt, top5_cnt = 0.0, 0.0\n",
        "    for i, label in enumerate(labels):\n",
        "      top1_cnt += label in pred_idx[i][:1]\n",
        "      top5_cnt += label in pred_idx[i][:5]\n",
        "      if i % 100 == 0:\n",
        "        print('Step {}: top1_acc = {:4.2f}%  top5_acc = {:4.2f}%'.format(\n",
        "            i, 100 * top1_cnt / (i + 1), 100 * top5_cnt / (i + 1)))\n",
        "        sys.stdout.flush()\n",
        "    top1, top5 = 100 * top1_cnt / num_images, 100 * top5_cnt / num_images\n",
        "    print('Final: top1_acc = {:4.2f}%  top5_acc = {:4.2f}%'.format(top1, top5))\n",
        "    return top1, top5"
      ],
      "metadata": {
        "id": "JrRodLCIi4RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *condconv_layers*.py"
      ],
      "metadata": {
        "id": "pk2y2Bg3jfma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"CondConv implementations in Tensorflow Layers.\n",
        "[1] Brandon Yang, Gabriel Bender, Quoc V. Le, Jiquan Ngiam\n",
        "  CondConv: Conditionally Parameterized Convolutions for Efficient Inference.\n",
        "  NeurIPS'19, https://arxiv.org/abs/1904.04971\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "\n",
        "def get_condconv_initializer(initializer, num_experts, expert_shape):\n",
        "  \"\"\"Wraps the initializer to correctly initialize CondConv variables.\n",
        "  CondConv initializes biases and kernels in a num_experts x num_params\n",
        "  matrix for efficient computation. This wrapper ensures that each expert\n",
        "  is correctly initialized with the given initializer before being flattened\n",
        "  into the correctly shaped CondConv variable.\n",
        "  Arguments:\n",
        "    initializer: The initializer to apply for each individual expert.\n",
        "    num_experts: The number of experts to be initialized.\n",
        "    expert_shape: The original shape of each individual expert.\n",
        "  Returns:\n",
        "    The initializer for the num_experts x num_params CondConv variable.\n",
        "  \"\"\"\n",
        "  def condconv_initializer(expected_shape, dtype=None, partition=None):\n",
        "    \"\"\"CondConv initializer function.\"\"\"\n",
        "    num_params = np.prod(expert_shape)\n",
        "    if (len(expected_shape) != 2 or expected_shape[0] != num_experts or\n",
        "        expected_shape[1] != num_params):\n",
        "      raise (ValueError(\n",
        "          'CondConv variables must have shape [num_experts, num_params]'))\n",
        "    flattened_kernels = []\n",
        "    for _ in range(num_experts):\n",
        "      kernel = initializer(expert_shape, dtype, partition)\n",
        "      flattened_kernels.append(tf.reshape(kernel, [-1]))\n",
        "    return tf.stack(flattened_kernels)\n",
        "\n",
        "  return condconv_initializer\n",
        "\n",
        "\n",
        "class CondConv2D(tf.keras.layers.Conv2D):\n",
        "  \"\"\"2D conditional convolution layer (e.g. spatial convolution over images).\n",
        "  Attributes:\n",
        "    filters: Integer, the dimensionality of the output space (i.e. the number of\n",
        "      output filters in the convolution).\n",
        "    kernel_size: An integer or tuple/list of 2 integers, specifying the height\n",
        "      and width of the 2D convolution window. Can be a single integer to specify\n",
        "      the same value for all spatial dimensions.\n",
        "    num_experts: The number of expert kernels and biases in the CondConv layer.\n",
        "    strides: An integer or tuple/list of 2 integers, specifying the strides of\n",
        "      the convolution along the height and width. Can be a single integer to\n",
        "      specify the same value for all spatial dimensions. Specifying any stride\n",
        "      value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n",
        "    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
        "    data_format: A string, one of `channels_last` (default) or `channels_first`.\n",
        "      The ordering of the dimensions in the inputs. `channels_last` corresponds\n",
        "      to inputs with shape `(batch, height, width, channels)` while\n",
        "      `channels_first` corresponds to inputs with shape `(batch, channels,\n",
        "      height, width)`. It defaults to the `image_data_format` value found in\n",
        "      your Keras config file at `~/.keras/keras.json`. If you never set it, then\n",
        "      it will be \"channels_last\".\n",
        "    dilation_rate: an integer or tuple/list of 2 integers, specifying the\n",
        "      dilation rate to use for dilated convolution. Can be a single integer to\n",
        "      specify the same value for all spatial dimensions. Currently, specifying\n",
        "      any `dilation_rate` value != 1 is incompatible with specifying any stride\n",
        "      value != 1.\n",
        "    activation: Activation function to use. If you don't specify anything, no\n",
        "      activation is applied\n",
        "      (ie. \"linear\" activation: `a(x) = x`).\n",
        "    use_bias: Boolean, whether the layer uses a bias vector.\n",
        "    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
        "    bias_initializer: Initializer for the bias vector.\n",
        "    kernel_regularizer: Regularizer function applied to the `kernel` weights\n",
        "      matrix.\n",
        "    bias_regularizer: Regularizer function applied to the bias vector.\n",
        "    activity_regularizer: Regularizer function applied to the output of the\n",
        "      layer (its \"activation\")..\n",
        "    kernel_constraint: Constraint function applied to the kernel matrix.\n",
        "    bias_constraint: Constraint function applied to the bias vector.\n",
        "  Input shape:\n",
        "    4D tensor with shape: `(samples, channels, rows, cols)` if\n",
        "      data_format='channels_first'\n",
        "    or 4D tensor with shape: `(samples, rows, cols, channels)` if\n",
        "      data_format='channels_last'.\n",
        "  Output shape:\n",
        "    4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n",
        "      data_format='channels_first'\n",
        "    or 4D tensor with shape: `(samples, new_rows, new_cols, filters)` if\n",
        "      data_format='channels_last'. `rows` and `cols` values might have changed\n",
        "      due to padding.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               filters,\n",
        "               kernel_size,\n",
        "               num_experts,\n",
        "               strides=(1, 1),\n",
        "               padding='valid',\n",
        "               data_format=None,\n",
        "               dilation_rate=(1, 1),\n",
        "               activation=None,\n",
        "               use_bias=True,\n",
        "               kernel_initializer='glorot_uniform',\n",
        "               bias_initializer='zeros',\n",
        "               kernel_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               activity_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               **kwargs):\n",
        "    super(CondConv2D, self).__init__(\n",
        "        filters=filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        data_format=data_format,\n",
        "        dilation_rate=dilation_rate,\n",
        "        activation=activation,\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        bias_initializer=bias_initializer,\n",
        "        kernel_regularizer=kernel_regularizer,\n",
        "        bias_regularizer=bias_regularizer,\n",
        "        activity_regularizer=activity_regularizer,\n",
        "        kernel_constraint=kernel_constraint,\n",
        "        bias_constraint=bias_constraint,\n",
        "        **kwargs)\n",
        "    if num_experts < 1:\n",
        "      raise ValueError('A CondConv layer must have at least one expert.')\n",
        "    self.num_experts = num_experts\n",
        "    if self.data_format == 'channels_first':\n",
        "      self.converted_data_format = 'NCHW'\n",
        "    else:\n",
        "      self.converted_data_format = 'NHWC'\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    if len(input_shape) != 4:\n",
        "      raise ValueError(\n",
        "          'Inputs to `CondConv2D` should have rank 4. '\n",
        "          'Received input shape:', str(input_shape))\n",
        "    input_shape = tf.TensorShape(input_shape)\n",
        "    channel_axis = self._get_channel_axis()\n",
        "    if input_shape.dims[channel_axis].value is None:\n",
        "      raise ValueError('The channel dimension of the inputs '\n",
        "                       'should be defined. Found `None`.')\n",
        "    input_dim = int(input_shape[channel_axis])\n",
        "\n",
        "    self.kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "    kernel_num_params = 1\n",
        "    for kernel_dim in self.kernel_shape:\n",
        "      kernel_num_params *= kernel_dim\n",
        "    condconv_kernel_shape = (self.num_experts, kernel_num_params)\n",
        "    self.condconv_kernel = self.add_weight(\n",
        "        name='condconv_kernel',\n",
        "        shape=condconv_kernel_shape,\n",
        "        initializer=get_condconv_initializer(self.kernel_initializer,\n",
        "                                             self.num_experts,\n",
        "                                             self.kernel_shape),\n",
        "        regularizer=self.kernel_regularizer,\n",
        "        constraint=self.kernel_constraint,\n",
        "        trainable=True,\n",
        "        dtype=self.dtype)\n",
        "\n",
        "    if self.use_bias:\n",
        "      self.bias_shape = (self.filters,)\n",
        "      condconv_bias_shape = (self.num_experts, self.filters)\n",
        "      self.condconv_bias = self.add_weight(\n",
        "          name='condconv_bias',\n",
        "          shape=condconv_bias_shape,\n",
        "          initializer=get_condconv_initializer(self.bias_initializer,\n",
        "                                               self.num_experts,\n",
        "                                               self.bias_shape),\n",
        "          regularizer=self.bias_regularizer,\n",
        "          constraint=self.bias_constraint,\n",
        "          trainable=True,\n",
        "          dtype=self.dtype)\n",
        "    else:\n",
        "      self.bias = None\n",
        "\n",
        "    self.input_spec = tf.layers.InputSpec(\n",
        "        ndim=self.rank + 2, axes={channel_axis: input_dim})\n",
        "\n",
        "    self.built = True\n",
        "\n",
        "  def call(self, inputs, routing_weights):\n",
        "    # Compute example dependent kernels\n",
        "    kernels = tf.matmul(routing_weights, self.condconv_kernel)\n",
        "    batch_size = inputs.shape[0].value\n",
        "    inputs = tf.split(inputs, batch_size, 0)\n",
        "    kernels = tf.split(kernels, batch_size, 0)\n",
        "    # Apply example-dependent convolution to each example in the batch\n",
        "    outputs_list = []\n",
        "    for input_tensor, kernel in zip(inputs, kernels):\n",
        "      kernel = tf.reshape(kernel, self.kernel_shape)\n",
        "      outputs_list.append(\n",
        "          tf.nn.convolution(\n",
        "              input_tensor,\n",
        "              kernel,\n",
        "              strides=self.strides,\n",
        "              padding=self._get_padding_op(),\n",
        "              dilations=self.dilation_rate,\n",
        "              data_format=self.converted_data_format))\n",
        "    outputs = tf.concat(outputs_list, 0)\n",
        "\n",
        "    if self.use_bias:\n",
        "      # Compute example-dependent biases\n",
        "      biases = tf.matmul(routing_weights, self.condconv_bias)\n",
        "      outputs = tf.split(outputs, batch_size, 0)\n",
        "      biases = tf.split(biases, batch_size, 0)\n",
        "      # Add example-dependent bias to each example in the batch\n",
        "      bias_outputs_list = []\n",
        "      for output, bias in zip(outputs, biases):\n",
        "        bias = tf.squeeze(bias, axis=0)\n",
        "        bias_outputs_list.append(\n",
        "            tf.nn.bias_add(output, bias,\n",
        "                           data_format=self.converted_data_format))\n",
        "      outputs = tf.concat(bias_outputs_list, 0)\n",
        "\n",
        "    if self.activation is not None:\n",
        "      return self.activation(outputs)\n",
        "    return outputs\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {'num_experts': self.num_experts}\n",
        "    base_config = super(CondConv2D, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "  def _get_channel_axis(self):\n",
        "    if self.data_format == 'channels_first':\n",
        "      return 1\n",
        "    else:\n",
        "      return -1\n",
        "\n",
        "  def _get_padding_op(self):\n",
        "    if self.padding == 'causal':\n",
        "      op_padding = 'valid'\n",
        "    else:\n",
        "      op_padding = self.padding\n",
        "    if not isinstance(op_padding, (list, tuple)):\n",
        "      op_padding = op_padding.upper()\n",
        "    return op_padding\n",
        "\n",
        "\n",
        "class DepthwiseCondConv2D(tf.keras.layers.DepthwiseConv2D):\n",
        "  \"\"\"Depthwise separable 2D conditional convolution layer.\n",
        "  This layer extends the base depthwise 2D convolution layer to compute\n",
        "  example-dependent parameters. A DepthwiseCondConv2D layer has 'num_experts`\n",
        "  kernels and biases. It computes a kernel and bias for each example as a\n",
        "  weighted sum of experts using the input example-dependent routing weights,\n",
        "  then applies the depthwise convolution to each example.\n",
        "  Attributes:\n",
        "    kernel_size: An integer or tuple/list of 2 integers, specifying the height\n",
        "      and width of the 2D convolution window. Can be a single integer to specify\n",
        "      the same value for all spatial dimensions.\n",
        "    num_experts: The number of expert kernels and biases in the\n",
        "      DepthwiseCondConv2D layer.\n",
        "    strides: An integer or tuple/list of 2 integers, specifying the strides of\n",
        "      the convolution along the height and width. Can be a single integer to\n",
        "      specify the same value for all spatial dimensions. Specifying any stride\n",
        "      value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n",
        "    padding: one of `'valid'` or `'same'` (case-insensitive).\n",
        "    depth_multiplier: The number of depthwise convolution output channels for\n",
        "      each input channel. The total number of depthwise convolution output\n",
        "      channels will be equal to `filters_in * depth_multiplier`.\n",
        "    data_format: A string, one of `channels_last` (default) or `channels_first`.\n",
        "      The ordering of the dimensions in the inputs. `channels_last` corresponds\n",
        "      to inputs with shape `(batch, height, width, channels)` while\n",
        "      `channels_first` corresponds to inputs with shape `(batch, channels,\n",
        "      height, width)`. It defaults to the `image_data_format` value found in\n",
        "      your Keras config file at `~/.keras/keras.json`. If you never set it, then\n",
        "      it will be 'channels_last'.\n",
        "    activation: Activation function to use. If you don't specify anything, no\n",
        "      activation is applied\n",
        "      (ie. 'linear' activation: `a(x) = x`).\n",
        "    use_bias: Boolean, whether the layer uses a bias vector.\n",
        "    depthwise_initializer: Initializer for the depthwise kernel matrix.\n",
        "    bias_initializer: Initializer for the bias vector.\n",
        "    depthwise_regularizer: Regularizer function applied to the depthwise kernel\n",
        "      matrix.\n",
        "    bias_regularizer: Regularizer function applied to the bias vector.\n",
        "    activity_regularizer: Regularizer function applied to the output of the\n",
        "      layer (its 'activation').\n",
        "    depthwise_constraint: Constraint function applied to the depthwise kernel\n",
        "      matrix.\n",
        "    bias_constraint: Constraint function applied to the bias vector.\n",
        "  Input shape:\n",
        "    4D tensor with shape: `[batch, channels, rows, cols]` if\n",
        "      data_format='channels_first'\n",
        "    or 4D tensor with shape: `[batch, rows, cols, channels]` if\n",
        "      data_format='channels_last'.\n",
        "  Output shape:\n",
        "    4D tensor with shape: `[batch, filters, new_rows, new_cols]` if\n",
        "      data_format='channels_first'\n",
        "    or 4D tensor with shape: `[batch, new_rows, new_cols, filters]` if\n",
        "      data_format='channels_last'. `rows` and `cols` values might have changed\n",
        "      due to padding.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               kernel_size,\n",
        "               num_experts,\n",
        "               strides=(1, 1),\n",
        "               padding='valid',\n",
        "               depth_multiplier=1,\n",
        "               data_format=None,\n",
        "               activation=None,\n",
        "               use_bias=True,\n",
        "               depthwise_initializer='glorot_uniform',\n",
        "               bias_initializer='zeros',\n",
        "               depthwise_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               activity_regularizer=None,\n",
        "               depthwise_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               **kwargs):\n",
        "    super(DepthwiseCondConv2D, self).__init__(\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        depth_multiplier=depth_multiplier,\n",
        "        data_format=data_format,\n",
        "        activation=activation,\n",
        "        use_bias=use_bias,\n",
        "        depthwise_initializer=depthwise_initializer,\n",
        "        bias_initializer=bias_initializer,\n",
        "        depthwise_regularizer=depthwise_regularizer,\n",
        "        bias_regularizer=bias_regularizer,\n",
        "        activity_regularizer=activity_regularizer,\n",
        "        depthwise_constraint=depthwise_constraint,\n",
        "        bias_constraint=bias_constraint,\n",
        "        **kwargs)\n",
        "    if num_experts < 1:\n",
        "      raise ValueError('A CondConv layer must have at least one expert.')\n",
        "    self.num_experts = num_experts\n",
        "    if self.data_format == 'channels_first':\n",
        "      self.converted_data_format = 'NCHW'\n",
        "    else:\n",
        "      self.converted_data_format = 'NHWC'\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    if len(input_shape) < 4:\n",
        "      raise ValueError(\n",
        "          'Inputs to `DepthwiseCondConv2D` should have rank 4. '\n",
        "          'Received input shape:', str(input_shape))\n",
        "    input_shape = tf.TensorShape(input_shape)\n",
        "    if self.data_format == 'channels_first':\n",
        "      channel_axis = 1\n",
        "    else:\n",
        "      channel_axis = 3\n",
        "    if input_shape.dims[channel_axis].value is None:\n",
        "      raise ValueError('The channel dimension of the inputs to '\n",
        "                       '`DepthwiseConv2D` '\n",
        "                       'should be defined. Found `None`.')\n",
        "    input_dim = int(input_shape[channel_axis])\n",
        "    self.depthwise_kernel_shape = (self.kernel_size[0], self.kernel_size[1],\n",
        "                                   input_dim, self.depth_multiplier)\n",
        "\n",
        "    depthwise_kernel_num_params = 1\n",
        "    for dim in self.depthwise_kernel_shape:\n",
        "      depthwise_kernel_num_params *= dim\n",
        "    depthwise_condconv_kernel_shape = (self.num_experts,\n",
        "                                       depthwise_kernel_num_params)\n",
        "\n",
        "    self.depthwise_condconv_kernel = self.add_weight(\n",
        "        shape=depthwise_condconv_kernel_shape,\n",
        "        initializer=get_condconv_initializer(self.depthwise_initializer,\n",
        "                                             self.num_experts,\n",
        "                                             self.depthwise_kernel_shape),\n",
        "        name='depthwise_condconv_kernel',\n",
        "        regularizer=self.depthwise_regularizer,\n",
        "        constraint=self.depthwise_constraint,\n",
        "        trainable=True)\n",
        "\n",
        "    if self.use_bias:\n",
        "      bias_dim = input_dim * self.depth_multiplier\n",
        "      self.bias_shape = (bias_dim,)\n",
        "      condconv_bias_shape = (self.num_experts, bias_dim)\n",
        "      self.condconv_bias = self.add_weight(\n",
        "          name='condconv_bias',\n",
        "          shape=condconv_bias_shape,\n",
        "          initializer=get_condconv_initializer(self.bias_initializer,\n",
        "                                               self.num_experts,\n",
        "                                               self.bias_shape),\n",
        "          regularizer=self.bias_regularizer,\n",
        "          constraint=self.bias_constraint,\n",
        "          trainable=True,\n",
        "          dtype=self.dtype)\n",
        "    else:\n",
        "      self.bias = None\n",
        "    # Set input spec.\n",
        "    self.input_spec = tf.layers.InputSpec(\n",
        "        ndim=4, axes={channel_axis: input_dim})\n",
        "    self.built = True\n",
        "\n",
        "  def call(self, inputs, routing_weights):\n",
        "    # Compute example dependent depthwise kernels\n",
        "    depthwise_kernels = tf.matmul(routing_weights,\n",
        "                                  self.depthwise_condconv_kernel)\n",
        "    batch_size = inputs.shape[0].value\n",
        "    inputs = tf.split(inputs, batch_size, 0)\n",
        "    depthwise_kernels = tf.split(depthwise_kernels, batch_size, 0)\n",
        "    # Apply example-dependent depthwise convolution to each example in the batch\n",
        "    outputs_list = []\n",
        "    for input_tensor, depthwise_kernel in zip(inputs, depthwise_kernels):\n",
        "      depthwise_kernel = tf.reshape(depthwise_kernel,\n",
        "                                    self.depthwise_kernel_shape)\n",
        "      if self.data_format == 'channels_first':\n",
        "        converted_strides = (1, 1) + self.strides\n",
        "      else:\n",
        "        converted_strides = (1,) + self.strides + (1,)\n",
        "      outputs_list.append(\n",
        "          tf.nn.depthwise_conv2d(\n",
        "              input_tensor,\n",
        "              depthwise_kernel,\n",
        "              strides=converted_strides,\n",
        "              padding=self.padding.upper(),\n",
        "              dilations=self.dilation_rate,\n",
        "              data_format=self.converted_data_format))\n",
        "    outputs = tf.concat(outputs_list, 0)\n",
        "\n",
        "    if self.use_bias:\n",
        "      # Compute example-dependent biases\n",
        "      biases = tf.matmul(routing_weights, self.condconv_bias)\n",
        "      outputs = tf.split(outputs, batch_size, 0)\n",
        "      biases = tf.split(biases, batch_size, 0)\n",
        "      # Add example-dependent bias to each example in the batch\n",
        "      bias_outputs_list = []\n",
        "      for output, bias in zip(outputs, biases):\n",
        "        bias = tf.squeeze(bias, axis=0)\n",
        "        bias_outputs_list.append(\n",
        "            tf.nn.bias_add(output, bias,\n",
        "                           data_format=self.converted_data_format))\n",
        "      outputs = tf.concat(bias_outputs_list, 0)\n",
        "\n",
        "    if self.activation is not None:\n",
        "      return self.activation(outputs)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {'num_experts': self.num_experts}\n",
        "    base_config = super(DepthwiseCondConv2D, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n"
      ],
      "metadata": {
        "id": "tSyCLjbVlYeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# efficientnet_builder.py"
      ],
      "metadata": {
        "id": "0qpyWRtvjtIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Model Builder for EfficientNet.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import re\n",
        "from absl import logging\n",
        "import numpy as np\n",
        "import six\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "#import efficientnet_model\n",
        "#import utils\n",
        "MEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
        "STDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n",
        "\n",
        "\n",
        "def efficientnet_params(model_name):\n",
        "  \"\"\"Get efficientnet params based on model name.\"\"\"\n",
        "  params_dict = {\n",
        "      # (width_coefficient, depth_coefficient, resolution, dropout_rate)\n",
        "      'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n",
        "      'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n",
        "      'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n",
        "      'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n",
        "      'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n",
        "      'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n",
        "      'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n",
        "      'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n",
        "      'efficientnet-b8': (2.2, 3.6, 672, 0.5),\n",
        "      'efficientnet-l2': (4.3, 5.3, 800, 0.5),\n",
        "  }\n",
        "  return params_dict[model_name]\n",
        "\n",
        "\n",
        "class BlockDecoder(object):\n",
        "  \"\"\"Block Decoder for readability.\"\"\"\n",
        "\n",
        "  def _decode_block_string(self, block_string):\n",
        "    \"\"\"Gets a block through a string notation of arguments.\"\"\"\n",
        "    if six.PY2:\n",
        "      assert isinstance(block_string, (str, unicode))\n",
        "    else:\n",
        "      assert isinstance(block_string, str)\n",
        "    ops = block_string.split('_')\n",
        "    options = {}\n",
        "    for op in ops:\n",
        "      splits = re.split(r'(\\d.*)', op)\n",
        "      if len(splits) >= 2:\n",
        "        key, value = splits[:2]\n",
        "        options[key] = value\n",
        "\n",
        "    if 's' not in options or len(options['s']) != 2:\n",
        "      raise ValueError('Strides options should be a pair of integers.')\n",
        "\n",
        "    return efficientnet_model.BlockArgs(\n",
        "        kernel_size=int(options['k']),\n",
        "        num_repeat=int(options['r']),\n",
        "        input_filters=int(options['i']),\n",
        "        output_filters=int(options['o']),\n",
        "        expand_ratio=int(options['e']),\n",
        "        id_skip=('noskip' not in block_string),\n",
        "        se_ratio=float(options['se']) if 'se' in options else None,\n",
        "        strides=[int(options['s'][0]),\n",
        "                 int(options['s'][1])],\n",
        "        conv_type=int(options['c']) if 'c' in options else 0,\n",
        "        fused_conv=int(options['f']) if 'f' in options else 0,\n",
        "        space2depth=int(options['d']) if 'd' in options else 0,\n",
        "        condconv=('cc' in block_string),\n",
        "        activation_fn=(tf.nn.relu if int(options['a']) == 0\n",
        "                       else tf.nn.swish) if 'a' in options else None)\n",
        "\n",
        "  def _encode_block_string(self, block):\n",
        "    \"\"\"Encodes a block to a string.\"\"\"\n",
        "    args = [\n",
        "        'r%d' % block.num_repeat,\n",
        "        'k%d' % block.kernel_size,\n",
        "        's%d%d' % (block.strides[0], block.strides[1]),\n",
        "        'e%s' % block.expand_ratio,\n",
        "        'i%d' % block.input_filters,\n",
        "        'o%d' % block.output_filters,\n",
        "        'c%d' % block.conv_type,\n",
        "        'f%d' % block.fused_conv,\n",
        "        'd%d' % block.space2depth,\n",
        "    ]\n",
        "    if block.se_ratio > 0 and block.se_ratio <= 1:\n",
        "      args.append('se%s' % block.se_ratio)\n",
        "    if block.id_skip is False:  # pylint: disable=g-bool-id-comparison\n",
        "      args.append('noskip')\n",
        "    if block.condconv:\n",
        "      args.append('cc')\n",
        "    return '_'.join(args)\n",
        "\n",
        "  def decode(self, string_list):\n",
        "    \"\"\"Decodes a list of string notations to specify blocks inside the network.\n",
        "    Args:\n",
        "      string_list: a list of strings, each string is a notation of block.\n",
        "    Returns:\n",
        "      A list of namedtuples to represent blocks arguments.\n",
        "    \"\"\"\n",
        "    assert isinstance(string_list, list)\n",
        "    blocks_args = []\n",
        "    for block_string in string_list:\n",
        "      blocks_args.append(self._decode_block_string(block_string))\n",
        "    return blocks_args\n",
        "\n",
        "  def encode(self, blocks_args):\n",
        "    \"\"\"Encodes a list of Blocks to a list of strings.\n",
        "    Args:\n",
        "      blocks_args: A list of namedtuples to represent blocks arguments.\n",
        "    Returns:\n",
        "      a list of strings, each string is a notation of block.\n",
        "    \"\"\"\n",
        "    block_strings = []\n",
        "    for block in blocks_args:\n",
        "      block_strings.append(self._encode_block_string(block))\n",
        "    return block_strings\n",
        "\n",
        "\n",
        "def swish(features, use_native=True, use_hard=False):\n",
        "  \"\"\"Computes the Swish activation function.\n",
        "  We provide three alternnatives:\n",
        "    - Native tf.nn.swish, use less memory during training than composable swish.\n",
        "    - Quantization friendly hard swish.\n",
        "    - A composable swish, equivalant to tf.nn.swish, but more general for\n",
        "      finetuning and TF-Hub.\n",
        "  Args:\n",
        "    features: A `Tensor` representing preactivation values.\n",
        "    use_native: Whether to use the native swish from tf.nn that uses a custom\n",
        "      gradient to reduce memory usage, or to use customized swish that uses\n",
        "      default TensorFlow gradient computation.\n",
        "    use_hard: Whether to use quantization-friendly hard swish.\n",
        "  Returns:\n",
        "    The activation value.\n",
        "  \"\"\"\n",
        "  if use_native and use_hard:\n",
        "    raise ValueError('Cannot specify both use_native and use_hard.')\n",
        "\n",
        "  if use_native:\n",
        "    return tf.nn.swish(features)\n",
        "\n",
        "  if use_hard:\n",
        "    return features * tf.nn.relu6(features + np.float32(3)) * (1. / 6.)\n",
        "\n",
        "  features = tf.convert_to_tensor(features, name='features')\n",
        "  return features * tf.nn.sigmoid(features)\n",
        "\n",
        "\n",
        "_DEFAULT_BLOCKS_ARGS = [\n",
        "    'r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25',\n",
        "    'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25',\n",
        "    'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25',\n",
        "    'r1_k3_s11_e6_i192_o320_se0.25',\n",
        "]\n",
        "\n",
        "\n",
        "def efficientnet(width_coefficient=None,\n",
        "                 depth_coefficient=None,\n",
        "                 dropout_rate=0.2,\n",
        "                 survival_prob=0.8):\n",
        "  \"\"\"Creates a efficientnet model.\"\"\"\n",
        "  global_params = efficientnet_model.GlobalParams(\n",
        "      blocks_args=_DEFAULT_BLOCKS_ARGS,\n",
        "      batch_norm_momentum=0.99,\n",
        "      batch_norm_epsilon=1e-3,\n",
        "      dropout_rate=dropout_rate,\n",
        "      survival_prob=survival_prob,\n",
        "      data_format='channels_last',\n",
        "      num_classes=1000,\n",
        "      width_coefficient=width_coefficient,\n",
        "      depth_coefficient=depth_coefficient,\n",
        "      depth_divisor=8,\n",
        "      min_depth=None,\n",
        "      relu_fn=tf.nn.swish,\n",
        "      # The default is TPU-specific batch norm.\n",
        "      # The alternative is tf.layers.BatchNormalization.\n",
        "      batch_norm=utils.train_batch_norm,  # TPU-specific requirement.\n",
        "      use_se=True,\n",
        "      clip_projection_output=False)\n",
        "  return global_params\n",
        "\n",
        "\n",
        "def get_model_params(model_name, override_params):\n",
        "  \"\"\"Get the block args and global params for a given model.\"\"\"\n",
        "  if model_name.startswith('efficientnet'):\n",
        "    width_coefficient, depth_coefficient, _, dropout_rate = (\n",
        "        efficientnet_params(model_name))\n",
        "    global_params = efficientnet(\n",
        "        width_coefficient, depth_coefficient, dropout_rate)\n",
        "  else:\n",
        "    raise NotImplementedError('model name is not pre-defined: %s' % model_name)\n",
        "\n",
        "  if override_params:\n",
        "    # ValueError will be raised here if override_params has fields not included\n",
        "    # in global_params.\n",
        "    global_params = global_params._replace(**override_params)\n",
        "\n",
        "  decoder = BlockDecoder()\n",
        "  blocks_args = decoder.decode(global_params.blocks_args)\n",
        "\n",
        "  logging.info('global_params= %s', global_params)\n",
        "  return blocks_args, global_params\n",
        "\n",
        "\n",
        "def build_model(images,\n",
        "                model_name,\n",
        "                training,\n",
        "                override_params=None,\n",
        "                model_dir=None,\n",
        "                fine_tuning=False,\n",
        "                features_only=False,\n",
        "                pooled_features_only=False):\n",
        "  \"\"\"A helper function to create a model and return predicted logits.\n",
        "  Args:\n",
        "    images: input images tensor.\n",
        "    model_name: string, the predefined model name.\n",
        "    training: boolean, whether the model is constructed for training.\n",
        "    override_params: A dictionary of params for overriding. Fields must exist in\n",
        "      efficientnet_model.GlobalParams.\n",
        "    model_dir: string, optional model dir for saving configs.\n",
        "    fine_tuning: boolean, whether the model is used for finetuning.\n",
        "    features_only: build the base feature network only (excluding final\n",
        "      1x1 conv layer, global pooling, dropout and fc head).\n",
        "    pooled_features_only: build the base network for features extraction (after\n",
        "      1x1 conv layer and global pooling, but before dropout and fc head).\n",
        "  Returns:\n",
        "    logits: the logits tensor of classes.\n",
        "    endpoints: the endpoints for each layer.\n",
        "  Raises:\n",
        "    When model_name specified an undefined model, raises NotImplementedError.\n",
        "    When override_params has invalid fields, raises ValueError.\n",
        "  \"\"\"\n",
        "  assert isinstance(images, tf.Tensor)\n",
        "  assert not (features_only and pooled_features_only)\n",
        "\n",
        "  # For backward compatibility.\n",
        "  if override_params and override_params.get('drop_connect_rate', None):\n",
        "    override_params['survival_prob'] = 1 - override_params['drop_connect_rate']\n",
        "\n",
        "  if not training or fine_tuning:\n",
        "    if not override_params:\n",
        "      override_params = {}\n",
        "    override_params['batch_norm'] = utils.eval_batch_norm\n",
        "    if fine_tuning:\n",
        "      override_params['relu_fn'] = functools.partial(swish, use_native=False)\n",
        "  blocks_args, global_params = get_model_params(model_name, override_params)\n",
        "\n",
        "  if model_dir:\n",
        "    param_file = os.path.join(model_dir, 'model_params.txt')\n",
        "    if not tf.gfile.Exists(param_file):\n",
        "      if not tf.gfile.Exists(model_dir):\n",
        "        tf.gfile.MakeDirs(model_dir)\n",
        "      with tf.gfile.GFile(param_file, 'w') as f:\n",
        "        logging.info('writing to %s', param_file)\n",
        "        f.write('model_name= %s\\n\\n' % model_name)\n",
        "        f.write('global_params= %s\\n\\n' % str(global_params))\n",
        "        f.write('blocks_args= %s\\n\\n' % str(blocks_args))\n",
        "\n",
        "  with tf.variable_scope(model_name):\n",
        "    model = efficientnet_model.Model(blocks_args, global_params)\n",
        "    outputs = model(\n",
        "        images,\n",
        "        training=training,\n",
        "        features_only=features_only,\n",
        "        pooled_features_only=pooled_features_only)\n",
        "  if features_only:\n",
        "    outputs = tf.identity(outputs, 'features')\n",
        "  elif pooled_features_only:\n",
        "    outputs = tf.identity(outputs, 'pooled_features')\n",
        "  else:\n",
        "    outputs = tf.identity(outputs, 'logits')\n",
        "  return outputs, model.endpoints\n",
        "\n",
        "\n",
        "def build_model_base(images, model_name, training, override_params=None):\n",
        "  \"\"\"Create a base feature network and return the features before pooling.\n",
        "  Args:\n",
        "    images: input images tensor.\n",
        "    model_name: string, the predefined model name.\n",
        "    training: boolean, whether the model is constructed for training.\n",
        "    override_params: A dictionary of params for overriding. Fields must exist in\n",
        "      efficientnet_model.GlobalParams.\n",
        "  Returns:\n",
        "    features: base features before pooling.\n",
        "    endpoints: the endpoints for each layer.\n",
        "  Raises:\n",
        "    When model_name specified an undefined model, raises NotImplementedError.\n",
        "    When override_params has invalid fields, raises ValueError.\n",
        "  \"\"\"\n",
        "  assert isinstance(images, tf.Tensor)\n",
        "  # For backward compatibility.\n",
        "  if override_params and override_params.get('drop_connect_rate', None):\n",
        "    override_params['survival_prob'] = 1 - override_params['drop_connect_rate']\n",
        "\n",
        "  blocks_args, global_params = get_model_params(model_name, override_params)\n",
        "\n",
        "  with tf.variable_scope(model_name):\n",
        "    model = efficientnet_model.Model(blocks_args, global_params)\n",
        "    features = model(images, training=training, features_only=True)\n",
        "\n",
        "  features = tf.identity(features, 'features')\n",
        "  return features, model.endpoints"
      ],
      "metadata": {
        "id": "8LaULfwQiFf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# efficientnet_model.py\n"
      ],
      "metadata": {
        "id": "uM1P0DfKj0C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Contains definitions for EfficientNet model.\n",
        "[1] Mingxing Tan, Quoc V. Le\n",
        "  EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.\n",
        "  ICML'19, https://arxiv.org/abs/1905.11946\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import functools\n",
        "import math\n",
        "\n",
        "from absl import logging\n",
        "import numpy as np\n",
        "import six\n",
        "from six.moves import xrange\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "#import utils\n",
        "#from condconv import condconv_layers\n",
        "\n",
        "GlobalParams = collections.namedtuple('GlobalParams', [\n",
        "    'batch_norm_momentum', 'batch_norm_epsilon', 'dropout_rate', 'data_format',\n",
        "    'num_classes', 'width_coefficient', 'depth_coefficient', 'depth_divisor',\n",
        "    'min_depth', 'survival_prob', 'relu_fn', 'batch_norm', 'use_se',\n",
        "    'se_coefficient', 'local_pooling', 'condconv_num_experts',\n",
        "    'clip_projection_output', 'blocks_args', 'fix_head_stem', 'use_bfloat16'\n",
        "])\n",
        "# Note: the default value of None is not necessarily valid. It is valid to leave\n",
        "# width_coefficient, depth_coefficient at None, which is treated as 1.0 (and\n",
        "# which also allows depth_divisor and min_depth to be left at None).\n",
        "GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n",
        "\n",
        "BlockArgs = collections.namedtuple('BlockArgs', [\n",
        "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
        "    'expand_ratio', 'id_skip', 'strides', 'se_ratio', 'conv_type', 'fused_conv',\n",
        "    'space2depth', 'condconv', 'activation_fn'\n",
        "])\n",
        "# defaults will be a public argument for namedtuple in Python 3.7\n",
        "# https://docs.python.org/3/library/collections.html#collections.namedtuple\n",
        "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n",
        "\n",
        "\n",
        "def conv_kernel_initializer(shape, dtype=None, partition_info=None):\n",
        "  \"\"\"Initialization for convolutional kernels.\n",
        "  The main difference with tf.variance_scaling_initializer is that\n",
        "  tf.variance_scaling_initializer uses a truncated normal with an uncorrected\n",
        "  standard deviation, whereas here we use a normal distribution. Similarly,\n",
        "  tf.initializers.variance_scaling uses a truncated normal with\n",
        "  a corrected standard deviation.\n",
        "  Args:\n",
        "    shape: shape of variable\n",
        "    dtype: dtype of variable\n",
        "    partition_info: unused\n",
        "  Returns:\n",
        "    an initialization for the variable\n",
        "  \"\"\"\n",
        "  del partition_info\n",
        "  kernel_height, kernel_width, _, out_filters = shape\n",
        "  fan_out = int(kernel_height * kernel_width * out_filters)\n",
        "  return tf.random_normal(\n",
        "      shape, mean=0.0, stddev=np.sqrt(2.0 / fan_out), dtype=dtype)\n",
        "\n",
        "\n",
        "def dense_kernel_initializer(shape, dtype=None, partition_info=None):\n",
        "  \"\"\"Initialization for dense kernels.\n",
        "  This initialization is equal to\n",
        "    tf.variance_scaling_initializer(scale=1.0/3.0, mode='fan_out',\n",
        "                                    distribution='uniform').\n",
        "  It is written out explicitly here for clarity.\n",
        "  Args:\n",
        "    shape: shape of variable\n",
        "    dtype: dtype of variable\n",
        "    partition_info: unused\n",
        "  Returns:\n",
        "    an initialization for the variable\n",
        "  \"\"\"\n",
        "  del partition_info\n",
        "  init_range = 1.0 / np.sqrt(shape[1])\n",
        "  return tf.random_uniform(shape, -init_range, init_range, dtype=dtype)\n",
        "\n",
        "\n",
        "def round_filters(filters, global_params, skip=False):\n",
        "  \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
        "  orig_f = filters\n",
        "  multiplier = global_params.width_coefficient\n",
        "  divisor = global_params.depth_divisor\n",
        "  min_depth = global_params.min_depth\n",
        "  if skip or not multiplier:\n",
        "    return filters\n",
        "\n",
        "  filters *= multiplier\n",
        "  min_depth = min_depth or divisor\n",
        "  new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)\n",
        "  # Make sure that round down does not go down by more than 10%.\n",
        "  if new_filters < 0.9 * filters:\n",
        "    new_filters += divisor\n",
        "  logging.info('round_filter input=%s output=%s', orig_f, new_filters)\n",
        "  return int(new_filters)\n",
        "\n",
        "\n",
        "def round_repeats(repeats, global_params, skip=False):\n",
        "  \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
        "  multiplier = global_params.depth_coefficient\n",
        "  if skip or not multiplier:\n",
        "    return repeats\n",
        "  return int(math.ceil(multiplier * repeats))\n",
        "\n",
        "\n",
        "class MBConvBlock(tf.keras.layers.Layer):\n",
        "  \"\"\"A class of MBConv: Mobile Inverted Residual Bottleneck.\n",
        "  Attributes:\n",
        "    endpoints: dict. A list of internal tensors.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, block_args, global_params):\n",
        "    \"\"\"Initializes a MBConv block.\n",
        "    Args:\n",
        "      block_args: BlockArgs, arguments to create a Block.\n",
        "      global_params: GlobalParams, a set of global parameters.\n",
        "    \"\"\"\n",
        "    super(MBConvBlock, self).__init__()\n",
        "    self._block_args = block_args\n",
        "    self._local_pooling = global_params.local_pooling\n",
        "    self._batch_norm_momentum = global_params.batch_norm_momentum\n",
        "    self._batch_norm_epsilon = global_params.batch_norm_epsilon\n",
        "    self._batch_norm = global_params.batch_norm\n",
        "    self._condconv_num_experts = global_params.condconv_num_experts\n",
        "    self._data_format = global_params.data_format\n",
        "    self._se_coefficient = global_params.se_coefficient\n",
        "    if self._data_format == 'channels_first':\n",
        "      self._channel_axis = 1\n",
        "      self._spatial_dims = [2, 3]\n",
        "    else:\n",
        "      self._channel_axis = -1\n",
        "      self._spatial_dims = [1, 2]\n",
        "\n",
        "    self._relu_fn = (self._block_args.activation_fn\n",
        "                     or global_params.relu_fn or tf.nn.swish)\n",
        "    self._has_se = (\n",
        "        global_params.use_se and self._block_args.se_ratio is not None and\n",
        "        0 < self._block_args.se_ratio <= 1)\n",
        "\n",
        "    self._clip_projection_output = global_params.clip_projection_output\n",
        "\n",
        "    self.endpoints = None\n",
        "\n",
        "    self.conv_cls = utils.Conv2D\n",
        "    self.depthwise_conv_cls = utils.DepthwiseConv2D\n",
        "    if self._block_args.condconv:\n",
        "      self.conv_cls = functools.partial(\n",
        "          condconv_layers.CondConv2D, num_experts=self._condconv_num_experts)\n",
        "      self.depthwise_conv_cls = functools.partial(\n",
        "          condconv_layers.DepthwiseCondConv2D,\n",
        "          num_experts=self._condconv_num_experts)\n",
        "\n",
        "    # Builds the block accordings to arguments.\n",
        "    self._build()\n",
        "\n",
        "  def block_args(self):\n",
        "    return self._block_args\n",
        "\n",
        "  def _build(self):\n",
        "    \"\"\"Builds block according to the arguments.\"\"\"\n",
        "    if self._block_args.space2depth == 1:\n",
        "      self._space2depth = tf.layers.Conv2D(\n",
        "          self._block_args.input_filters,\n",
        "          kernel_size=[2, 2],\n",
        "          strides=[2, 2],\n",
        "          kernel_initializer=conv_kernel_initializer,\n",
        "          padding='same',\n",
        "          data_format=self._data_format,\n",
        "          use_bias=False)\n",
        "      self._bnsp = self._batch_norm(\n",
        "          axis=self._channel_axis,\n",
        "          momentum=self._batch_norm_momentum,\n",
        "          epsilon=self._batch_norm_epsilon)\n",
        "\n",
        "    if self._block_args.condconv:\n",
        "      # Add the example-dependent routing function\n",
        "      self._avg_pooling = tf.keras.layers.GlobalAveragePooling2D(\n",
        "          data_format=self._data_format)\n",
        "      self._routing_fn = tf.layers.Dense(\n",
        "          self._condconv_num_experts, activation=tf.nn.sigmoid)\n",
        "\n",
        "    filters = self._block_args.input_filters * self._block_args.expand_ratio\n",
        "    kernel_size = self._block_args.kernel_size\n",
        "\n",
        "    # Fused expansion phase. Called if using fused convolutions.\n",
        "    self._fused_conv = self.conv_cls(\n",
        "        filters=filters,\n",
        "        kernel_size=[kernel_size, kernel_size],\n",
        "        strides=self._block_args.strides,\n",
        "        kernel_initializer=conv_kernel_initializer,\n",
        "        padding='same',\n",
        "        data_format=self._data_format,\n",
        "        use_bias=False)\n",
        "\n",
        "    # Expansion phase. Called if not using fused convolutions and expansion\n",
        "    # phase is necessary.\n",
        "    self._expand_conv = self.conv_cls(\n",
        "        filters=filters,\n",
        "        kernel_size=[1, 1],\n",
        "        strides=[1, 1],\n",
        "        kernel_initializer=conv_kernel_initializer,\n",
        "        padding='same',\n",
        "        data_format=self._data_format,\n",
        "        use_bias=False)\n",
        "    self._bn0 = self._batch_norm(\n",
        "        axis=self._channel_axis,\n",
        "        momentum=self._batch_norm_momentum,\n",
        "        epsilon=self._batch_norm_epsilon)\n",
        "\n",
        "    # Depth-wise convolution phase. Called if not using fused convolutions.\n",
        "    self._depthwise_conv = self.depthwise_conv_cls(\n",
        "        kernel_size=[kernel_size, kernel_size],\n",
        "        strides=self._block_args.strides,\n",
        "        depthwise_initializer=conv_kernel_initializer,\n",
        "        padding='same',\n",
        "        data_format=self._data_format,\n",
        "        use_bias=False)\n",
        "\n",
        "    self._bn1 = self._batch_norm(\n",
        "        axis=self._channel_axis,\n",
        "        momentum=self._batch_norm_momentum,\n",
        "        epsilon=self._batch_norm_epsilon)\n",
        "\n",
        "    if self._has_se:\n",
        "      num_reduced_filters = int(self._block_args.input_filters * (\n",
        "          self._block_args.se_ratio * (self._se_coefficient\n",
        "                                       if self._se_coefficient else 1)))\n",
        "      # account for space2depth transformation in SE filter depth, since\n",
        "      # the SE compression ratio is w.r.t. the original filter depth before\n",
        "      # space2depth is applied.\n",
        "      num_reduced_filters = (num_reduced_filters // 4\n",
        "                             if self._block_args.space2depth == 1\n",
        "                             else num_reduced_filters)\n",
        "      num_reduced_filters = max(1, num_reduced_filters)\n",
        "      # Squeeze and Excitation layer.\n",
        "      self._se_reduce = utils.Conv2D(\n",
        "          num_reduced_filters,\n",
        "          kernel_size=[1, 1],\n",
        "          strides=[1, 1],\n",
        "          kernel_initializer=conv_kernel_initializer,\n",
        "          padding='same',\n",
        "          data_format=self._data_format,\n",
        "          use_bias=True)\n",
        "      self._se_expand = utils.Conv2D(\n",
        "          filters,\n",
        "          kernel_size=[1, 1],\n",
        "          strides=[1, 1],\n",
        "          kernel_initializer=conv_kernel_initializer,\n",
        "          padding='same',\n",
        "          data_format=self._data_format,\n",
        "          use_bias=True)\n",
        "\n",
        "    # Output phase.\n",
        "    filters = self._block_args.output_filters\n",
        "    self._project_conv = self.conv_cls(\n",
        "        filters=filters,\n",
        "        kernel_size=[1, 1],\n",
        "        strides=[1, 1],\n",
        "        kernel_initializer=conv_kernel_initializer,\n",
        "        padding='same',\n",
        "        data_format=self._data_format,\n",
        "        use_bias=False)\n",
        "    self._bn2 = self._batch_norm(\n",
        "        axis=self._channel_axis,\n",
        "        momentum=self._batch_norm_momentum,\n",
        "        epsilon=self._batch_norm_epsilon)\n",
        "\n",
        "  def _call_se(self, input_tensor):\n",
        "    \"\"\"Call Squeeze and Excitation layer.\n",
        "    Args:\n",
        "      input_tensor: Tensor, a single input tensor for Squeeze/Excitation layer.\n",
        "    Returns:\n",
        "      A output tensor, which should have the same shape as input.\n",
        "    \"\"\"\n",
        "    if self._local_pooling:\n",
        "      shape = input_tensor.get_shape().as_list()\n",
        "      kernel_size = [\n",
        "          1, shape[self._spatial_dims[0]], shape[self._spatial_dims[1]], 1]\n",
        "      se_tensor = tf.nn.avg_pool(\n",
        "          input_tensor,\n",
        "          ksize=kernel_size,\n",
        "          strides=[1, 1, 1, 1],\n",
        "          padding='VALID',\n",
        "          data_format=self._data_format)\n",
        "    else:\n",
        "      se_tensor = tf.reduce_mean(\n",
        "          input_tensor, self._spatial_dims, keepdims=True)\n",
        "    se_tensor = self._se_expand(self._relu_fn(self._se_reduce(se_tensor)))\n",
        "    logging.info('Built SE %s : %s', self.name, se_tensor.shape)\n",
        "    return tf.sigmoid(se_tensor) * input_tensor\n",
        "\n",
        "  def call(self, inputs, training=True, survival_prob=None):\n",
        "    \"\"\"Implementation of call().\n",
        "    Args:\n",
        "      inputs: the inputs tensor.\n",
        "      training: boolean, whether the model is constructed for training.\n",
        "      survival_prob: float, between 0 to 1, drop connect rate.\n",
        "    Returns:\n",
        "      A output tensor.\n",
        "    \"\"\"\n",
        "    logging.info('Block %s input shape: %s', self.name, inputs.shape)\n",
        "    x = inputs\n",
        "\n",
        "    fused_conv_fn = self._fused_conv\n",
        "    expand_conv_fn = self._expand_conv\n",
        "    depthwise_conv_fn = self._depthwise_conv\n",
        "    project_conv_fn = self._project_conv\n",
        "\n",
        "    if self._block_args.condconv:\n",
        "      pooled_inputs = self._avg_pooling(inputs)\n",
        "      routing_weights = self._routing_fn(pooled_inputs)\n",
        "      # Capture routing weights as additional input to CondConv layers\n",
        "      fused_conv_fn = functools.partial(\n",
        "          self._fused_conv, routing_weights=routing_weights)\n",
        "      expand_conv_fn = functools.partial(\n",
        "          self._expand_conv, routing_weights=routing_weights)\n",
        "      depthwise_conv_fn = functools.partial(\n",
        "          self._depthwise_conv, routing_weights=routing_weights)\n",
        "      project_conv_fn = functools.partial(\n",
        "          self._project_conv, routing_weights=routing_weights)\n",
        "\n",
        "    # creates conv 2x2 kernel\n",
        "    if self._block_args.space2depth == 1:\n",
        "      with tf.variable_scope('space2depth'):\n",
        "        x = self._relu_fn(\n",
        "            self._bnsp(self._space2depth(x), training=training))\n",
        "      logging.info('Block start with space2depth shape: %s', x.shape)\n",
        "\n",
        "    if self._block_args.fused_conv:\n",
        "      # If use fused mbconv, skip expansion and use regular conv.\n",
        "      x = self._relu_fn(self._bn1(fused_conv_fn(x), training=training))\n",
        "      logging.info('Conv2D shape: %s', x.shape)\n",
        "    else:\n",
        "      # Otherwise, first apply expansion and then apply depthwise conv.\n",
        "      if self._block_args.expand_ratio != 1:\n",
        "        x = self._relu_fn(self._bn0(expand_conv_fn(x), training=training))\n",
        "        logging.info('Expand shape: %s', x.shape)\n",
        "\n",
        "      x = self._relu_fn(self._bn1(depthwise_conv_fn(x), training=training))\n",
        "      logging.info('DWConv shape: %s', x.shape)\n",
        "\n",
        "    if self._has_se:\n",
        "      with tf.variable_scope('se'):\n",
        "        x = self._call_se(x)\n",
        "\n",
        "    self.endpoints = {'expansion_output': x}\n",
        "\n",
        "    x = self._bn2(project_conv_fn(x), training=training)\n",
        "    # Add identity so that quantization-aware training can insert quantization\n",
        "    # ops correctly.\n",
        "    x = tf.identity(x)\n",
        "    if self._clip_projection_output:\n",
        "      x = tf.clip_by_value(x, -6, 6)\n",
        "    if self._block_args.id_skip:\n",
        "      if all(\n",
        "          s == 1 for s in self._block_args.strides\n",
        "      ) and inputs.get_shape().as_list()[-1] == x.get_shape().as_list()[-1]:\n",
        "        # Apply only if skip connection presents.\n",
        "        if survival_prob:\n",
        "          x = utils.drop_connect(x, training, survival_prob)\n",
        "        x = tf.add(x, inputs)\n",
        "    logging.info('Project shape: %s', x.shape)\n",
        "    return x\n",
        "\n",
        "\n",
        "class MBConvBlockWithoutDepthwise(MBConvBlock):\n",
        "  \"\"\"MBConv-like block without depthwise convolution and squeeze-and-excite.\"\"\"\n",
        "\n",
        "  def _build(self):\n",
        "    \"\"\"Builds block according to the arguments.\"\"\"\n",
        "    filters = self._block_args.input_filters * self._block_args.expand_ratio\n",
        "    if self._block_args.expand_ratio != 1:\n",
        "      # Expansion phase:\n",
        "      self._expand_conv = tf.layers.Conv2D(\n",
        "          filters,\n",
        "          kernel_size=[3, 3],\n",
        "          strides=self._block_args.strides,\n",
        "          kernel_initializer=conv_kernel_initializer,\n",
        "          padding='same',\n",
        "          use_bias=False)\n",
        "      self._bn0 = self._batch_norm(\n",
        "          axis=self._channel_axis,\n",
        "          momentum=self._batch_norm_momentum,\n",
        "          epsilon=self._batch_norm_epsilon)\n",
        "\n",
        "    # Output phase:\n",
        "    filters = self._block_args.output_filters\n",
        "    self._project_conv = tf.layers.Conv2D(\n",
        "        filters,\n",
        "        kernel_size=[1, 1],\n",
        "        strides=[1, 1],\n",
        "        kernel_initializer=conv_kernel_initializer,\n",
        "        padding='same',\n",
        "        use_bias=False)\n",
        "    self._bn1 = self._batch_norm(\n",
        "        axis=self._channel_axis,\n",
        "        momentum=self._batch_norm_momentum,\n",
        "        epsilon=self._batch_norm_epsilon)\n",
        "\n",
        "  def call(self, inputs, training=True, survival_prob=None):\n",
        "    \"\"\"Implementation of call().\n",
        "    Args:\n",
        "      inputs: the inputs tensor.\n",
        "      training: boolean, whether the model is constructed for training.\n",
        "      survival_prob: float, between 0 to 1, drop connect rate.\n",
        "    Returns:\n",
        "      A output tensor.\n",
        "    \"\"\"\n",
        "    logging.info('Block input shape: %s', inputs.shape)\n",
        "    if self._block_args.expand_ratio != 1:\n",
        "      x = self._relu_fn(self._bn0(self._expand_conv(inputs), training=training))\n",
        "    else:\n",
        "      x = inputs\n",
        "    logging.info('Expand shape: %s', x.shape)\n",
        "\n",
        "    self.endpoints = {'expansion_output': x}\n",
        "\n",
        "    x = self._bn1(self._project_conv(x), training=training)\n",
        "    # Add identity so that quantization-aware training can insert quantization\n",
        "    # ops correctly.\n",
        "    x = tf.identity(x)\n",
        "    if self._clip_projection_output:\n",
        "      x = tf.clip_by_value(x, -6, 6)\n",
        "\n",
        "    if self._block_args.id_skip:\n",
        "      if all(\n",
        "          s == 1 for s in self._block_args.strides\n",
        "      ) and self._block_args.input_filters == self._block_args.output_filters:\n",
        "        # Apply only if skip connection presents.\n",
        "        if survival_prob:\n",
        "          x = utils.drop_connect(x, training, survival_prob)\n",
        "        x = tf.add(x, inputs)\n",
        "    logging.info('Project shape: %s', x.shape)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Model(tf.keras.Model):\n",
        "  \"\"\"A class implements tf.keras.Model for MNAS-like model.\n",
        "    Reference: https://arxiv.org/abs/1807.11626\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, blocks_args=None, global_params=None):\n",
        "    \"\"\"Initializes an `Model` instance.\n",
        "    Args:\n",
        "      blocks_args: A list of BlockArgs to construct block modules.\n",
        "      global_params: GlobalParams, a set of global parameters.\n",
        "    Raises:\n",
        "      ValueError: when blocks_args is not specified as a list.\n",
        "    \"\"\"\n",
        "    super(Model, self).__init__()\n",
        "    if not isinstance(blocks_args, list):\n",
        "      raise ValueError('blocks_args should be a list.')\n",
        "    self._global_params = global_params\n",
        "    self._blocks_args = blocks_args\n",
        "    self._relu_fn = global_params.relu_fn or tf.nn.swish\n",
        "    self._batch_norm = global_params.batch_norm\n",
        "    self._fix_head_stem = global_params.fix_head_stem\n",
        "\n",
        "    self.endpoints = None\n",
        "\n",
        "    self._build()\n",
        "\n",
        "  def _get_conv_block(self, conv_type):\n",
        "    conv_block_map = {0: MBConvBlock, 1: MBConvBlockWithoutDepthwise}\n",
        "    return conv_block_map[conv_type]\n",
        "\n",
        "  def _build(self):\n",
        "    \"\"\"Builds a model.\"\"\"\n",
        "    self._blocks = []\n",
        "    batch_norm_momentum = self._global_params.batch_norm_momentum\n",
        "    batch_norm_epsilon = self._global_params.batch_norm_epsilon\n",
        "    if self._global_params.data_format == 'channels_first':\n",
        "      channel_axis = 1\n",
        "      self._spatial_dims = [2, 3]\n",
        "    else:\n",
        "      channel_axis = -1\n",
        "      self._spatial_dims = [1, 2]\n",
        "\n",
        "    # Stem part.\n",
        "    self._conv_stem = utils.Conv2D(\n",
        "        filters=round_filters(32, self._global_params, self._fix_head_stem),\n",
        "        kernel_size=[3, 3],\n",
        "        strides=[2, 2],\n",
        "        kernel_initializer=conv_kernel_initializer,\n",
        "        padding='same',\n",
        "        data_format=self._global_params.data_format,\n",
        "        use_bias=False)\n",
        "    self._bn0 = self._batch_norm(\n",
        "        axis=channel_axis,\n",
        "        momentum=batch_norm_momentum,\n",
        "        epsilon=batch_norm_epsilon)\n",
        "\n",
        "    # Builds blocks.\n",
        "    for i, block_args in enumerate(self._blocks_args):\n",
        "      assert block_args.num_repeat > 0\n",
        "      assert block_args.space2depth in [0, 1, 2]\n",
        "      # Update block input and output filters based on depth multiplier.\n",
        "      input_filters = round_filters(block_args.input_filters,\n",
        "                                    self._global_params)\n",
        "\n",
        "      output_filters = round_filters(block_args.output_filters,\n",
        "                                     self._global_params)\n",
        "      kernel_size = block_args.kernel_size\n",
        "      if self._fix_head_stem and (i == 0 or i == len(self._blocks_args) - 1):\n",
        "        repeats = block_args.num_repeat\n",
        "      else:\n",
        "        repeats = round_repeats(block_args.num_repeat, self._global_params)\n",
        "      block_args = block_args._replace(\n",
        "          input_filters=input_filters,\n",
        "          output_filters=output_filters,\n",
        "          num_repeat=repeats)\n",
        "\n",
        "      # The first block needs to take care of stride and filter size increase.\n",
        "      conv_block = self._get_conv_block(block_args.conv_type)\n",
        "      if not block_args.space2depth:  #  no space2depth at all\n",
        "        self._blocks.append(conv_block(block_args, self._global_params))\n",
        "      else:\n",
        "        # if space2depth, adjust filters, kernels, and strides.\n",
        "        depth_factor = int(4 / block_args.strides[0] / block_args.strides[1])\n",
        "        block_args = block_args._replace(\n",
        "            input_filters=block_args.input_filters * depth_factor,\n",
        "            output_filters=block_args.output_filters * depth_factor,\n",
        "            kernel_size=((block_args.kernel_size + 1) // 2 if depth_factor > 1\n",
        "                         else block_args.kernel_size))\n",
        "        # if the first block has stride-2 and space2depth transformation\n",
        "        if (block_args.strides[0] == 2 and block_args.strides[1] == 2):\n",
        "          block_args = block_args._replace(strides=[1, 1])\n",
        "          self._blocks.append(conv_block(block_args, self._global_params))\n",
        "          block_args = block_args._replace(  # sp stops at stride-2\n",
        "              space2depth=0,\n",
        "              input_filters=input_filters,\n",
        "              output_filters=output_filters,\n",
        "              kernel_size=kernel_size)\n",
        "        elif block_args.space2depth == 1:\n",
        "          self._blocks.append(conv_block(block_args, self._global_params))\n",
        "          block_args = block_args._replace(space2depth=2)\n",
        "        else:\n",
        "          self._blocks.append(conv_block(block_args, self._global_params))\n",
        "      if block_args.num_repeat > 1:  # rest of blocks with the same block_arg\n",
        "        # pylint: disable=protected-access\n",
        "        block_args = block_args._replace(\n",
        "            input_filters=block_args.output_filters, strides=[1, 1])\n",
        "        # pylint: enable=protected-access\n",
        "      for _ in xrange(block_args.num_repeat - 1):\n",
        "        self._blocks.append(conv_block(block_args, self._global_params))\n",
        "\n",
        "    # Head part.\n",
        "    self._conv_head = utils.Conv2D(\n",
        "        filters=round_filters(1280, self._global_params, self._fix_head_stem),\n",
        "        kernel_size=[1, 1],\n",
        "        strides=[1, 1],\n",
        "        kernel_initializer=conv_kernel_initializer,\n",
        "        padding='same',\n",
        "        data_format=self._global_params.data_format,\n",
        "        use_bias=False)\n",
        "    self._bn1 = self._batch_norm(\n",
        "        axis=channel_axis,\n",
        "        momentum=batch_norm_momentum,\n",
        "        epsilon=batch_norm_epsilon)\n",
        "\n",
        "    self._avg_pooling = tf.keras.layers.GlobalAveragePooling2D(\n",
        "        data_format=self._global_params.data_format)\n",
        "    if self._global_params.num_classes:\n",
        "      self._fc = tf.layers.Dense(\n",
        "          self._global_params.num_classes,\n",
        "          kernel_initializer=dense_kernel_initializer)\n",
        "    else:\n",
        "      self._fc = None\n",
        "\n",
        "    if self._global_params.dropout_rate > 0:\n",
        "      self._dropout = tf.keras.layers.Dropout(self._global_params.dropout_rate)\n",
        "    else:\n",
        "      self._dropout = None\n",
        "\n",
        "  def call(self,\n",
        "           inputs,\n",
        "           training=True,\n",
        "           features_only=None,\n",
        "           pooled_features_only=False):\n",
        "    \"\"\"Implementation of call().\n",
        "    Args:\n",
        "      inputs: input tensors.\n",
        "      training: boolean, whether the model is constructed for training.\n",
        "      features_only: build the base feature network only.\n",
        "      pooled_features_only: build the base network for features extraction\n",
        "        (after 1x1 conv layer and global pooling, but before dropout and fc\n",
        "        head).\n",
        "    Returns:\n",
        "      output tensors.\n",
        "    \"\"\"\n",
        "    outputs = None\n",
        "    self.endpoints = {}\n",
        "    reduction_idx = 0\n",
        "    # Calls Stem layers\n",
        "    with tf.variable_scope('stem'):\n",
        "      outputs = self._relu_fn(\n",
        "          self._bn0(self._conv_stem(inputs), training=training))\n",
        "    logging.info('Built stem layers with output shape: %s', outputs.shape)\n",
        "    self.endpoints['stem'] = outputs\n",
        "\n",
        "    # Calls blocks.\n",
        "    for idx, block in enumerate(self._blocks):\n",
        "      is_reduction = False  # reduction flag for blocks after the stem layer\n",
        "      # If the first block has space-to-depth layer, then stem is\n",
        "      # the first reduction point.\n",
        "      if (block.block_args().space2depth == 1 and idx == 0):\n",
        "        reduction_idx += 1\n",
        "        self.endpoints['reduction_%s' % reduction_idx] = outputs\n",
        "\n",
        "      elif ((idx == len(self._blocks) - 1) or\n",
        "            self._blocks[idx + 1].block_args().strides[0] > 1):\n",
        "        is_reduction = True\n",
        "        reduction_idx += 1\n",
        "\n",
        "      with tf.variable_scope('blocks_%s' % idx):\n",
        "        survival_prob = self._global_params.survival_prob\n",
        "        if survival_prob:\n",
        "          drop_rate = 1.0 - survival_prob\n",
        "          survival_prob = 1.0 - drop_rate * float(idx) / len(self._blocks)\n",
        "          logging.info('block_%s survival_prob: %s', idx, survival_prob)\n",
        "        outputs = block.call(\n",
        "            outputs, training=training, survival_prob=survival_prob)\n",
        "        self.endpoints['block_%s' % idx] = outputs\n",
        "        if is_reduction:\n",
        "          self.endpoints['reduction_%s' % reduction_idx] = outputs\n",
        "        if block.endpoints:\n",
        "          for k, v in six.iteritems(block.endpoints):\n",
        "            self.endpoints['block_%s/%s' % (idx, k)] = v\n",
        "            if is_reduction:\n",
        "              self.endpoints['reduction_%s/%s' % (reduction_idx, k)] = v\n",
        "    self.endpoints['features'] = outputs\n",
        "\n",
        "    if not features_only:\n",
        "      # Calls final layers and returns logits.\n",
        "      with tf.variable_scope('head'):\n",
        "        outputs = self._relu_fn(\n",
        "            self._bn1(self._conv_head(outputs), training=training))\n",
        "        self.endpoints['head_1x1'] = outputs\n",
        "\n",
        "        if self._global_params.local_pooling:\n",
        "          shape = outputs.get_shape().as_list()\n",
        "          kernel_size = [\n",
        "              1, shape[self._spatial_dims[0]], shape[self._spatial_dims[1]], 1]\n",
        "          outputs = tf.nn.avg_pool(\n",
        "              outputs, ksize=kernel_size, strides=[1, 1, 1, 1], padding='VALID')\n",
        "          self.endpoints['pooled_features'] = outputs\n",
        "          if not pooled_features_only:\n",
        "            if self._dropout:\n",
        "              outputs = self._dropout(outputs, training=training)\n",
        "            self.endpoints['global_pool'] = outputs\n",
        "            if self._fc:\n",
        "              outputs = tf.squeeze(outputs, self._spatial_dims)\n",
        "              outputs = self._fc(outputs)\n",
        "            self.endpoints['head'] = outputs\n",
        "        else:\n",
        "          outputs = self._avg_pooling(outputs)\n",
        "          self.endpoints['pooled_features'] = outputs\n",
        "          if not pooled_features_only:\n",
        "            if self._dropout:\n",
        "              outputs = self._dropout(outputs, training=training)\n",
        "            self.endpoints['global_pool'] = outputs\n",
        "            if self._fc:\n",
        "              outputs = self._fc(outputs)\n",
        "            self.endpoints['head'] = outputs\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "WaOLcxlgkcgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# efficientnet_lite_model_qat.py\n"
      ],
      "metadata": {
        "id": "3P8IekZGkOLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Implements EfficientNet Lite model for Quantization Aware Training.\n",
        "[1] Mingxing Tan, Quoc V. Le\n",
        "  EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.\n",
        "  ICML'19, https://arxiv.org/abs/1905.11946\n",
        "\"\"\"\n",
        "import functools\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "#import efficientnet_model\n",
        "\n",
        "\n",
        "class FunctionalModelBuilder:\n",
        "  \"\"\"A class that builds functional api keras models.\"\"\"\n",
        "\n",
        "  def __init__(self, name='FunctionalModel'):\n",
        "    self.name = name\n",
        "    self.built = False\n",
        "\n",
        "  def build(self, input_shape: tf.TensorShape):\n",
        "    del input_shape  # Only used by subclasses.\n",
        "    self.built = True\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    raise NotImplementedError('This function is implemented in subclasses.')\n",
        "\n",
        "  def get_functional_model(self, input_shape, training):\n",
        "    functional_inputs = tf.keras.Input(\n",
        "        shape=input_shape[1:], batch_size=input_shape[0])\n",
        "    functional_outputs = self(functional_inputs, training)\n",
        "    return tf.keras.Model(inputs=functional_inputs, outputs=functional_outputs)\n",
        "\n",
        "  def __call__(self, inputs, training):\n",
        "    if not self.built:\n",
        "      if tf.nest.is_nested(inputs):\n",
        "        input_shapes = [\n",
        "            input_tensor.shape for input_tensor in tf.nest.flatten(inputs)\n",
        "        ]\n",
        "      else:\n",
        "        input_shapes = inputs.shape\n",
        "      self.build(input_shapes[1:])\n",
        "    return self.call(inputs, training)\n",
        "\n",
        "\n",
        "class FunctionalMBConvBlock(FunctionalModelBuilder):\n",
        "  \"\"\"A class of MBConv: Mobile Inverted Residual Bottleneck.\n",
        "  Attributes:\n",
        "    endpoints: dict. A list of internal tensors.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, block_args, global_params, dtype, name, **kwargs):\n",
        "    \"\"\"Initializes a MBConv block.\n",
        "    Args:\n",
        "      block_args: BlockArgs, arguments to create a Block.\n",
        "      global_params: GlobalParams, a set of global parameters.\n",
        "      dtype: Layer type.\n",
        "      name: Layer name.\n",
        "      **kwargs: Keyword arguments.\n",
        "    \"\"\"\n",
        "    super().__init__(**kwargs)\n",
        "    self._block_args = block_args\n",
        "    self._dtype = dtype\n",
        "    self._name = name\n",
        "    self._batch_norm_momentum = global_params.batch_norm_momentum\n",
        "    self._batch_norm_epsilon = global_params.batch_norm_epsilon\n",
        "    self._batch_norm = global_params.batch_norm\n",
        "    self._data_format = global_params.data_format\n",
        "    self._conv_kernel_initializer = tf.compat.v2.keras.initializers.VarianceScaling(\n",
        "        scale=2.0, mode='fan_out', distribution='untruncated_normal')\n",
        "    if self._data_format == 'channels_first':\n",
        "      self._channel_axis = 1\n",
        "      self._spatial_dims = [2, 3]\n",
        "    else:\n",
        "      self._channel_axis = -1\n",
        "      self._spatial_dims = [1, 2]\n",
        "\n",
        "    self._relu_fn = functools.partial(tf.keras.layers.ReLU, 6.0)\n",
        "    self._survival_prob = global_params.survival_prob\n",
        "\n",
        "    self.endpoints = None\n",
        "\n",
        "  def block_args(self):\n",
        "    return self._block_args\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    \"\"\"Builds block according to the arguments.\"\"\"\n",
        "    conv2d_id = 0\n",
        "    batch_norm_id = 0\n",
        "    if self._block_args.expand_ratio != 1:\n",
        "      self._expand_conv = tf.keras.layers.Conv2D(\n",
        "          filters=(self._block_args.input_filters *\n",
        "                   self._block_args.expand_ratio),\n",
        "          kernel_size=[1, 1],\n",
        "          strides=[1, 1],\n",
        "          kernel_initializer=self._conv_kernel_initializer,\n",
        "          padding='same',\n",
        "          data_format=self._data_format,\n",
        "          use_bias=False,\n",
        "          dtype=self._dtype,\n",
        "          name=f'{self._name}/conv2d')\n",
        "      conv2d_id += 1\n",
        "      self._bn0 = self._batch_norm(\n",
        "          axis=self._channel_axis,\n",
        "          momentum=self._batch_norm_momentum,\n",
        "          epsilon=self._batch_norm_epsilon,\n",
        "          dtype=self._dtype,\n",
        "          name=f'{self._name}/tpu_batch_normalization')\n",
        "      batch_norm_id += 1\n",
        "\n",
        "    self._depthwise_conv = tf.keras.layers.DepthwiseConv2D(\n",
        "        kernel_size=[\n",
        "            self._block_args.kernel_size, self._block_args.kernel_size\n",
        "        ],\n",
        "        strides=self._block_args.strides,\n",
        "        depthwise_initializer=self._conv_kernel_initializer,\n",
        "        padding='same',\n",
        "        data_format=self._data_format,\n",
        "        use_bias=False,\n",
        "        dtype=self._dtype,\n",
        "        name=f'{self._name}/depthwise_conv2d')\n",
        "\n",
        "    batch_norm_name_suffix = f'_{batch_norm_id}' if batch_norm_id else ''\n",
        "    self._bn1 = self._batch_norm(\n",
        "        axis=self._channel_axis,\n",
        "        momentum=self._batch_norm_momentum,\n",
        "        epsilon=self._batch_norm_epsilon,\n",
        "        dtype=self._dtype,\n",
        "        name=f'{self._name}/tpu_batch_normalization{batch_norm_name_suffix}')\n",
        "    batch_norm_id += 1\n",
        "\n",
        "    # Output phase.\n",
        "    conv2d_name_suffix = f'_{conv2d_id}' if conv2d_id else ''\n",
        "    self._project_conv = tf.keras.layers.Conv2D(\n",
        "        filters=self._block_args.output_filters,\n",
        "        kernel_size=[1, 1],\n",
        "        strides=[1, 1],\n",
        "        kernel_initializer=self._conv_kernel_initializer,\n",
        "        padding='same',\n",
        "        data_format=self._data_format,\n",
        "        use_bias=False,\n",
        "        dtype=self._dtype,\n",
        "        name=f'{self._name}/conv2d{conv2d_name_suffix}')\n",
        "    batch_norm_name_suffix = f'_{batch_norm_id}' if batch_norm_id else ''\n",
        "    self._bn2 = self._batch_norm(\n",
        "        axis=self._channel_axis,\n",
        "        momentum=self._batch_norm_momentum,\n",
        "        epsilon=self._batch_norm_epsilon,\n",
        "        dtype=self._dtype,\n",
        "        name=f'{self._name}/tpu_batch_normalization{batch_norm_name_suffix}')\n",
        "    self._spartial_dropout_2d = tf.keras.layers.SpatialDropout2D(\n",
        "        rate=1 - self._survival_prob, dtype=self._dtype)\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    \"\"\"Implementation of call().\n",
        "    Args:\n",
        "      inputs: the inputs tensor.\n",
        "      training: boolean, whether the model is constructed for training.\n",
        "    Returns:\n",
        "      A output tensor.\n",
        "    \"\"\"\n",
        "    x = inputs\n",
        "\n",
        "    if self._block_args.expand_ratio != 1:\n",
        "      x = self._relu_fn()(self._bn0(self._expand_conv(x), training=training))\n",
        "\n",
        "    x = self._relu_fn()(self._bn1(self._depthwise_conv(x), training=training))\n",
        "    self.endpoints = {'expansion_output': x}\n",
        "\n",
        "    x = self._bn2(self._project_conv(x), training=training)\n",
        "\n",
        "    if (all(s == 1 for s in self._block_args.strides) and\n",
        "        inputs.get_shape().as_list()[-1] == x.get_shape().as_list()[-1]):\n",
        "      # Apply only if skip connection presents.\n",
        "      if self._survival_prob:\n",
        "        x = self._spartial_dropout_2d(x)\n",
        "      x = tf.keras.layers.Add(dtype=self._dtype)([x, inputs])\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class FunctionalModel(FunctionalModelBuilder):\n",
        "  \"\"\"A class implements tf.keras.Model for MNAS-like model.\n",
        "    Reference: https://arxiv.org/abs/1807.11626\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               model_name,\n",
        "               blocks_args=None,\n",
        "               global_params=None,\n",
        "               features_only=None,\n",
        "               pooled_features_only=False,\n",
        "               **kwargs):\n",
        "    \"\"\"Initializes an `Model` instance.\n",
        "    Args:\n",
        "      model_name: Name of the model.\n",
        "      blocks_args: A list of BlockArgs to construct block modules.\n",
        "      global_params: GlobalParams, a set of global parameters.\n",
        "      features_only: build the base feature network only.\n",
        "      pooled_features_only: build the base network for features extraction\n",
        "        (after 1x1 conv layer and global pooling, but before dropout and fc\n",
        "        head).\n",
        "      **kwargs: Keyword arguments.\n",
        "    Raises:\n",
        "      ValueError: when blocks_args is not specified as a list.\n",
        "    \"\"\"\n",
        "    super().__init__(**kwargs)\n",
        "    if not isinstance(blocks_args, list):\n",
        "      raise ValueError('blocks_args should be a list.')\n",
        "    self._model_name = model_name\n",
        "    self._global_params = global_params\n",
        "    self._blocks_args = blocks_args\n",
        "    self._dtype = 'float32'\n",
        "    if self._global_params.use_bfloat16:\n",
        "      self._dtype = 'mixed_bfloat16'\n",
        "    self._features_only = features_only\n",
        "    self._pooled_features_only = pooled_features_only\n",
        "    self._relu_fn = functools.partial(tf.keras.layers.ReLU, 6.0)\n",
        "    self._batch_norm = global_params.batch_norm\n",
        "    self._fix_head_stem = global_params.fix_head_stem\n",
        "    self._conv_kernel_initializer = tf.compat.v2.keras.initializers.VarianceScaling(\n",
        "        scale=2.0, mode='fan_out', distribution='untruncated_normal')\n",
        "    self._dense_kernel_initializer = tf.keras.initializers.VarianceScaling(\n",
        "        scale=1.0 / 3.0, mode='fan_out', distribution='uniform')\n",
        "    self.endpoints = None\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    \"\"\"Builds a model.\"\"\"\n",
        "    del input_shape  # Unused.\n",
        "    self._blocks = []\n",
        "    batch_norm_momentum = self._global_params.batch_norm_momentum\n",
        "    batch_norm_epsilon = self._global_params.batch_norm_epsilon\n",
        "    if self._global_params.data_format == 'channels_first':\n",
        "      channel_axis = 1\n",
        "      self._spatial_dims = [2, 3]\n",
        "    else:\n",
        "      channel_axis = -1\n",
        "      self._spatial_dims = [1, 2]\n",
        "\n",
        "    # Stem part.\n",
        "    self._conv_stem = tf.keras.layers.Conv2D(\n",
        "        filters=efficientnet_model.round_filters(32, self._global_params,\n",
        "                                                 self._fix_head_stem),\n",
        "        kernel_size=[3, 3],\n",
        "        strides=[2, 2],\n",
        "        kernel_initializer=self._conv_kernel_initializer,\n",
        "        padding='same',\n",
        "        data_format=self._global_params.data_format,\n",
        "        use_bias=False,\n",
        "        dtype=self._dtype,\n",
        "        name=f'{self._model_name}/stem/conv2d')\n",
        "    self._bn0 = self._batch_norm(\n",
        "        axis=channel_axis,\n",
        "        momentum=batch_norm_momentum,\n",
        "        epsilon=batch_norm_epsilon,\n",
        "        name=f'{self._model_name}/stem/tpu_batch_normalization')\n",
        "\n",
        "    # Builds blocks.\n",
        "    for i, block_args in enumerate(self._blocks_args):\n",
        "      assert block_args.num_repeat > 0\n",
        "      assert block_args.space2depth in [0, 1, 2]\n",
        "      # Update block input and output filters based on depth multiplier.\n",
        "      input_filters = efficientnet_model.round_filters(block_args.input_filters,\n",
        "                                                       self._global_params)\n",
        "\n",
        "      output_filters = efficientnet_model.round_filters(\n",
        "          block_args.output_filters, self._global_params)\n",
        "      if self._fix_head_stem and (i == 0 or i == len(self._blocks_args) - 1):\n",
        "        repeats = block_args.num_repeat\n",
        "      else:\n",
        "        repeats = efficientnet_model.round_repeats(block_args.num_repeat,\n",
        "                                                   self._global_params)\n",
        "      block_args = block_args._replace(\n",
        "          input_filters=input_filters,\n",
        "          output_filters=output_filters,\n",
        "          num_repeat=repeats)\n",
        "\n",
        "      # The first block needs to take care of stride and filter size increase.\n",
        "      self._blocks.append(\n",
        "          FunctionalMBConvBlock(\n",
        "              block_args=block_args,\n",
        "              global_params=self._global_params,\n",
        "              dtype=self._dtype,\n",
        "              name=f'{self._model_name}/blocks_{len(self._blocks)}'))\n",
        "\n",
        "      if block_args.num_repeat > 1:  # rest of blocks with the same block_arg\n",
        "        # pylint: disable=protected-access\n",
        "        block_args = block_args._replace(\n",
        "            input_filters=block_args.output_filters, strides=[1, 1])\n",
        "        # pylint: enable=protected-access\n",
        "      for _ in range(block_args.num_repeat - 1):\n",
        "        self._blocks.append(\n",
        "            FunctionalMBConvBlock(\n",
        "                block_args,\n",
        "                self._global_params,\n",
        "                dtype=self._dtype,\n",
        "                name=f'{self._model_name}/blocks_{len(self._blocks)}'))\n",
        "\n",
        "    # Head part.\n",
        "    self._conv_head = tf.keras.layers.Conv2D(\n",
        "        filters=efficientnet_model.round_filters(1280, self._global_params,\n",
        "                                                 self._fix_head_stem),\n",
        "        kernel_size=[1, 1],\n",
        "        strides=[1, 1],\n",
        "        kernel_initializer=self._conv_kernel_initializer,\n",
        "        padding='same',\n",
        "        data_format=self._global_params.data_format,\n",
        "        use_bias=False,\n",
        "        dtype=self._dtype,\n",
        "        name=f'{self._model_name}/head/conv2d')\n",
        "    self._bn1 = self._batch_norm(\n",
        "        axis=channel_axis,\n",
        "        momentum=batch_norm_momentum,\n",
        "        epsilon=batch_norm_epsilon,\n",
        "        dtype=self._dtype,\n",
        "        name=f'{self._model_name}/head/tpu_batch_normalization')\n",
        "\n",
        "    if self._global_params.num_classes:\n",
        "      self._fc = tf.keras.layers.Dense(\n",
        "          self._global_params.num_classes,\n",
        "          kernel_initializer=self._dense_kernel_initializer,\n",
        "          dtype=self._dtype,\n",
        "          name=f'{self._model_name}/head/dense')\n",
        "    else:\n",
        "      self._fc = None\n",
        "\n",
        "    if self._global_params.dropout_rate > 0:\n",
        "      self._dropout = tf.keras.layers.Dropout(\n",
        "          self._global_params.dropout_rate, dtype=self._dtype)\n",
        "    else:\n",
        "      self._dropout = None\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    \"\"\"Implementation of call().\n",
        "    Args:\n",
        "      inputs: input tensors.\n",
        "      training: boolean, whether the model is constructed for training.\n",
        "    Returns:\n",
        "      output tensors.\n",
        "    \"\"\"\n",
        "    outputs = None\n",
        "    self.endpoints = {}\n",
        "    reduction_idx = 0\n",
        "\n",
        "    # Calls Stem layers\n",
        "    outputs = self._relu_fn()(\n",
        "        self._bn0(self._conv_stem(inputs), training=training))\n",
        "    self.endpoints['stem'] = outputs\n",
        "\n",
        "    # Calls blocks.\n",
        "    for idx, block in enumerate(self._blocks):\n",
        "      is_reduction = False  # reduction flag for blocks after the stem layer\n",
        "      if ((idx == len(self._blocks) - 1) or\n",
        "          self._blocks[idx + 1].block_args().strides[0] > 1):\n",
        "        is_reduction = True\n",
        "        reduction_idx += 1\n",
        "\n",
        "      survival_prob = self._global_params.survival_prob\n",
        "      if survival_prob:\n",
        "        drop_rate = 1.0 - survival_prob\n",
        "        survival_prob = 1.0 - drop_rate * float(idx) / len(self._blocks)\n",
        "      outputs = block(outputs, training)\n",
        "      self.endpoints['block_%s' % idx] = outputs\n",
        "\n",
        "      if is_reduction:\n",
        "        self.endpoints['reduction_%s' % reduction_idx] = outputs\n",
        "      if block.endpoints:\n",
        "        for k, v in block.endpoints.items():\n",
        "          self.endpoints['block_%s/%s' % (idx, k)] = v\n",
        "          if is_reduction:\n",
        "            self.endpoints['reduction_%s/%s' % (reduction_idx, k)] = v\n",
        "    self.endpoints['features'] = outputs\n",
        "\n",
        "    if not self._features_only:\n",
        "      outputs = self._relu_fn()(\n",
        "          self._bn1(self._conv_head(outputs), training=training))\n",
        "      self.endpoints['head_1x1'] = outputs\n",
        "\n",
        "      shape = outputs.get_shape().as_list()\n",
        "      outputs = tf.keras.layers.AveragePooling2D(\n",
        "          pool_size=(shape[self._spatial_dims[0]],\n",
        "                     shape[self._spatial_dims[1]]),\n",
        "          strides=[1, 1],\n",
        "          padding='valid',\n",
        "          dtype=self._dtype)(\n",
        "              outputs)\n",
        "      self.endpoints['pooled_features'] = outputs\n",
        "      if not self._pooled_features_only:\n",
        "        if self._dropout:\n",
        "          outputs = self._dropout(outputs)\n",
        "        self.endpoints['global_pool'] = outputs\n",
        "        if self._fc:\n",
        "          outputs = tf.keras.layers.Flatten(dtype=self._dtype)(outputs)\n",
        "          outputs = self._fc(outputs)\n",
        "        self.endpoints['head'] = outputs\n",
        "\n",
        "    return [outputs] + list(\n",
        "        filter(lambda endpoint: endpoint is not None, [\n",
        "            self.endpoints.get('reduction_1'),\n",
        "            self.endpoints.get('reduction_2'),\n",
        "            self.endpoints.get('reduction_3'),\n",
        "            self.endpoints.get('reduction_4'),\n",
        "            self.endpoints.get('reduction_5'),\n",
        "        ]))"
      ],
      "metadata": {
        "id": "7WeiqYUwwTJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# efficientnet_lite_builder"
      ],
      "metadata": {
        "id": "jvZX1U3mj866"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Model Builder for EfficientNet Edge Models.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "from absl import logging\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "#import efficientnet_builder\n",
        "#import efficientnet_model\n",
        "#import utils\n",
        "#from lite import efficientnet_lite_model_qat\n",
        "# Edge models use inception-style MEAN and STDDEV for better post-quantization.\n",
        "MEAN_RGB = [127.0, 127.0, 127.0]\n",
        "STDDEV_RGB = [128.0, 128.0, 128.0]\n",
        "\n",
        "\n",
        "def efficientnet_lite_params(model_name):\n",
        "  \"\"\"Get efficientnet params based on model name.\"\"\"\n",
        "  if '-qat' in model_name:\n",
        "    model_name = model_name[:model_name.find('-qat')]\n",
        "  params_dict = {\n",
        "      # (width_coefficient, depth_coefficient, resolution, dropout_rate)\n",
        "      'efficientnet-lite0': (1.0, 1.0, 224, 0.2),\n",
        "      'efficientnet-lite1': (1.0, 1.1, 240, 0.2),\n",
        "      'efficientnet-lite2': (1.1, 1.2, 260, 0.3),\n",
        "      'efficientnet-lite3': (1.2, 1.4, 280, 0.3),\n",
        "      'efficientnet-lite4': (1.4, 1.8, 300, 0.3),\n",
        "  }\n",
        "  return params_dict[model_name]\n",
        "\n",
        "\n",
        "_DEFAULT_BLOCKS_ARGS = [\n",
        "    'r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25',\n",
        "    'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25',\n",
        "    'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25',\n",
        "    'r1_k3_s11_e6_i192_o320_se0.25',\n",
        "]\n",
        "\n",
        "\n",
        "def efficientnet_lite(width_coefficient=None,\n",
        "                      depth_coefficient=None,\n",
        "                      dropout_rate=0.2,\n",
        "                      survival_prob=0.8):\n",
        "  \"\"\"Creates a efficientnet model.\"\"\"\n",
        "  global_params = efficientnet_model.GlobalParams(\n",
        "      blocks_args=_DEFAULT_BLOCKS_ARGS,\n",
        "      batch_norm_momentum=0.99,\n",
        "      batch_norm_epsilon=1e-3,\n",
        "      dropout_rate=dropout_rate,\n",
        "      survival_prob=survival_prob,\n",
        "      data_format='channels_last',\n",
        "      num_classes=1000,\n",
        "      width_coefficient=width_coefficient,\n",
        "      depth_coefficient=depth_coefficient,\n",
        "      depth_divisor=8,\n",
        "      min_depth=None,\n",
        "      relu_fn=tf.nn.relu6,  # Relu6 is for easier quantization.\n",
        "      # The default is TPU-specific batch norm.\n",
        "      # The alternative is tf.layers.BatchNormalization.\n",
        "      batch_norm=utils.TpuBatchNormalization,  # TPU-specific requirement.\n",
        "      clip_projection_output=False,\n",
        "      fix_head_stem=True,  # Don't scale stem and head.\n",
        "      local_pooling=True,  # special cases for tflite issues.\n",
        "      use_se=False,  # SE is not well supported on many lite devices.\n",
        "      use_bfloat16=False)  # This flag is only read by QAT version of the model.\n",
        "  return global_params\n",
        "\n",
        "\n",
        "def get_model_params(model_name, override_params):\n",
        "  \"\"\"Get the block args and global params for a given model.\"\"\"\n",
        "  if model_name.startswith('efficientnet-lite'):\n",
        "    width_coefficient, depth_coefficient, _, dropout_rate = (\n",
        "        efficientnet_lite_params(model_name))\n",
        "    global_params = efficientnet_lite(\n",
        "        width_coefficient, depth_coefficient, dropout_rate)\n",
        "  else:\n",
        "    raise NotImplementedError('model name is not pre-defined: %s' % model_name)\n",
        "\n",
        "  if override_params:\n",
        "    # ValueError will be raised here if override_params has fields not included\n",
        "    # in global_params.\n",
        "    global_params = global_params._replace(**override_params)\n",
        "\n",
        "  decoder = efficientnet_builder.BlockDecoder()\n",
        "  blocks_args = decoder.decode(global_params.blocks_args)\n",
        "\n",
        "  logging.info('global_params= %s', global_params)\n",
        "  return blocks_args, global_params\n",
        "\n",
        "\n",
        "def build_model(images,\n",
        "                model_name,\n",
        "                training,\n",
        "                override_params=None,\n",
        "                model_dir=None,\n",
        "                fine_tuning=False,\n",
        "                features_only=False,\n",
        "                pooled_features_only=False):\n",
        "  \"\"\"A helper function to create a model and return predicted logits.\n",
        "  Args:\n",
        "    images: input images tensor.\n",
        "    model_name: string, the predefined model name.\n",
        "    training: boolean, whether the model is constructed for training.\n",
        "    override_params: A dictionary of params for overriding. Fields must exist in\n",
        "      efficientnet_model.GlobalParams.\n",
        "    model_dir: string, optional model dir for saving configs.\n",
        "    fine_tuning: boolean, whether the model is used for finetuning.\n",
        "    features_only: build the base feature network only (excluding final\n",
        "      1x1 conv layer, global pooling, dropout and fc head).\n",
        "    pooled_features_only: build the base network for features extraction (after\n",
        "      1x1 conv layer and global pooling, but before dropout and fc head).\n",
        "  Returns:\n",
        "    logits: the logits tensor of classes.\n",
        "    endpoints: the endpoints for each layer.\n",
        "  Raises:\n",
        "    When model_name specified an undefined model, raises NotImplementedError.\n",
        "    When override_params has invalid fields, raises ValueError.\n",
        "  \"\"\"\n",
        "  assert isinstance(images, tf.Tensor)\n",
        "  assert not (features_only and pooled_features_only)\n",
        "\n",
        "  # For backward compatibility.\n",
        "  if override_params and override_params.get('drop_connect_rate', None):\n",
        "    override_params['survival_prob'] = 1 - override_params['drop_connect_rate']\n",
        "\n",
        "  if '-qat' in model_name:\n",
        "    model_name = model_name[:model_name.find('-qat')]\n",
        "    with_quantization_aware_training = True\n",
        "  else:\n",
        "    with_quantization_aware_training = False\n",
        "\n",
        "  if not training or fine_tuning:\n",
        "    if not override_params:\n",
        "      override_params = {}\n",
        "    override_params['batch_norm'] = utils.BatchNormalization\n",
        "  blocks_args, global_params = get_model_params(model_name, override_params)\n",
        "\n",
        "  if model_dir:\n",
        "    param_file = os.path.join(model_dir, 'model_params.txt')\n",
        "    if not tf.gfile.Exists(param_file):\n",
        "      if not tf.gfile.Exists(model_dir):\n",
        "        tf.gfile.MakeDirs(model_dir)\n",
        "      with tf.gfile.GFile(param_file, 'w') as f:\n",
        "        logging.info('writing to %s', param_file)\n",
        "        f.write('model_name= %s\\n\\n' % model_name)\n",
        "        f.write('global_params= %s\\n\\n' % str(global_params))\n",
        "        f.write('blocks_args= %s\\n\\n' % str(blocks_args))\n",
        "\n",
        "  with tf.variable_scope(model_name):\n",
        "    if with_quantization_aware_training:\n",
        "      model = efficientnet_lite_model_qat.FunctionalModel(\n",
        "          model_name, blocks_args, global_params, features_only,\n",
        "          pooled_features_only)\n",
        "      outputs = model(images, training=training)[0]\n",
        "    else:\n",
        "      model = efficientnet_model.Model(blocks_args, global_params)\n",
        "      outputs = model(\n",
        "          images,\n",
        "          training=training,\n",
        "          features_only=features_only,\n",
        "          pooled_features_only=pooled_features_only)\n",
        "  if features_only:\n",
        "    outputs = tf.identity(outputs, 'features')\n",
        "  elif pooled_features_only:\n",
        "    outputs = tf.identity(outputs, 'pooled_features')\n",
        "  else:\n",
        "    outputs = tf.identity(outputs, 'logits')\n",
        "  return outputs, model.endpoints\n",
        "\n",
        "\n",
        "def build_model_base(images, model_name, training, override_params=None):\n",
        "  \"\"\"Create a base feature network and return the features before pooling.\n",
        "  Args:\n",
        "    images: input images tensor.\n",
        "    model_name: string, the predefined model name.\n",
        "    training: boolean, whether the model is constructed for training.\n",
        "    override_params: A dictionary of params for overriding. Fields must exist in\n",
        "      efficientnet_model.GlobalParams.\n",
        "  Returns:\n",
        "    features: base features before pooling.\n",
        "    endpoints: the endpoints for each layer.\n",
        "  Raises:\n",
        "    When model_name specified an undefined model, raises NotImplementedError.\n",
        "    When override_params has invalid fields, raises ValueError.\n",
        "  \"\"\"\n",
        "  assert isinstance(images, tf.Tensor)\n",
        "  # For backward compatibility.\n",
        "  if override_params and override_params.get('drop_connect_rate', None):\n",
        "    override_params['survival_prob'] = 1 - override_params['drop_connect_rate']\n",
        "\n",
        "  blocks_args, global_params = get_model_params(model_name, override_params)\n",
        "\n",
        "  with tf.variable_scope(model_name):\n",
        "    model = efficientnet_model.Model(blocks_args, global_params)\n",
        "    features = model(images, training=training, features_only=True)\n",
        "\n",
        "  features = tf.identity(features, 'features')\n",
        "  return features, model.endpoints"
      ],
      "metadata": {
        "id": "LwQXK1gFvh9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *efficientnet_lite_builder_test*.py\n"
      ],
      "metadata": {
        "id": "lxl2TQj6kB0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Tests for efficientnet_lite_builder.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "#from lite import efficientnet_lite_builder\n",
        "\n",
        "\n",
        "class EfficientnetBuilderTest(tf.test.TestCase):\n",
        "\n",
        "  def _test_model_params(self,\n",
        "                         model_name,\n",
        "                         input_size,\n",
        "                         expected_params,\n",
        "                         override_params=None,\n",
        "                         features_only=False,\n",
        "                         pooled_features_only=False):\n",
        "    images = tf.zeros((1, input_size, input_size, 3), dtype=tf.float32)\n",
        "    efficientnet_lite_builder.build_model(\n",
        "        images,\n",
        "        model_name=model_name,\n",
        "        override_params=override_params,\n",
        "        training=True,\n",
        "        features_only=features_only,\n",
        "        pooled_features_only=pooled_features_only)\n",
        "    num_params = np.sum([np.prod(v.shape) for v in tf.trainable_variables()])\n",
        "\n",
        "    self.assertEqual(num_params, expected_params)\n",
        "\n",
        "  def test_efficientnet_b0(self):\n",
        "    self._test_model_params(\n",
        "        'efficientnet-lite0', 224, expected_params=4652008)\n",
        "\n",
        "  def test_efficientnet_b1(self):\n",
        "    self._test_model_params(\n",
        "        'efficientnet-lite1', 240, expected_params=5416680)\n",
        "\n",
        "  def test_efficientnet_b2(self):\n",
        "    self._test_model_params(\n",
        "        'efficientnet-lite2', 260, expected_params=6092072)\n",
        "\n",
        "  def test_efficientnet_b3(self):\n",
        "    self._test_model_params(\n",
        "        'efficientnet-lite3', 280, expected_params=8197096)\n",
        "\n",
        "  def test_efficientnet_b4(self):\n",
        "    self._test_model_params(\n",
        "        'efficientnet-lite4', 300, expected_params=13006568)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.test.main()"
      ],
      "metadata": {
        "id": "BbcORBrQwCQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# efficientnet_lite_model_qat_test.py \n"
      ],
      "metadata": {
        "id": "Gwy0OUYykqPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Tests for efficientnet_lite_model_qat.\"\"\"\n",
        "\n",
        "from absl.testing import parameterized\n",
        "import tensorflow as tf\n",
        "#import tensorflow_model_optimization as tfmot\n",
        "\n",
        "#from lite import efficientnet_lite_builder\n",
        "#from lite import efficientnet_lite_model_qat\n",
        "\n",
        "\n",
        "class EfficientnetLiteModelQatTest(parameterized.TestCase, tf.test.TestCase):\n",
        "\n",
        "  @parameterized.parameters(('efficientnet-lite0',), ('efficientnet-lite1'),\n",
        "                            ('efficientnet-lite2',), ('efficientnet-lite3',),\n",
        "                            ('efficientnet-lite4',))\n",
        "  def test_values_match(self, model_name):\n",
        "    images = tf.random.stateless_uniform((1, 224, 224, 3), seed=(2, 3))\n",
        "\n",
        "    tf.random.set_seed(0)\n",
        "    outputs, _ = efficientnet_lite_builder.build_model(\n",
        "        images,\n",
        "        model_name=model_name,\n",
        "        override_params=None,\n",
        "        training=False,\n",
        "        features_only=False,\n",
        "        pooled_features_only=False)\n",
        "\n",
        "    tf.random.set_seed(0)\n",
        "    outputs_qat, _ = efficientnet_lite_builder.build_model(\n",
        "        images,\n",
        "        model_name=model_name + '-qat',\n",
        "        override_params=None,\n",
        "        training=False,\n",
        "        features_only=False,\n",
        "        pooled_features_only=False)\n",
        "\n",
        "    self.assertAllClose(tf.reduce_sum(outputs), tf.reduce_sum(outputs_qat))\n",
        "\n",
        "  @parameterized.parameters(('efficientnet-lite0',), ('efficientnet-lite1'),\n",
        "                            ('efficientnet-lite2',), ('efficientnet-lite3',),\n",
        "                            ('efficientnet-lite4',))\n",
        "  def test_model_quantizable(self, model_name):\n",
        "    images = tf.random.stateless_uniform((1, 224, 224, 3), seed=(2, 3))\n",
        "    override_params = {}\n",
        "    override_params['batch_norm'] = tf.keras.layers.BatchNormalization\n",
        "    blocks_args, global_params = efficientnet_lite_builder.get_model_params(\n",
        "        model_name, override_params=override_params)\n",
        "    model_qat = efficientnet_lite_model_qat.FunctionalModel(\n",
        "        model_name=model_name,\n",
        "        blocks_args=blocks_args,\n",
        "        global_params=global_params,\n",
        "        features_only=False,\n",
        "        pooled_features_only=False).get_functional_model(\n",
        "            training=True, input_shape=images.shape)\n",
        "    try:\n",
        "      tfmot.quantization.keras.quantize_model(model_qat)\n",
        "    except Exception as e:  # pylint: disable=broad-except\n",
        "      self.fail('Exception raised: %s' % str(e))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.test.main()"
      ],
      "metadata": {
        "id": "6T1L6wfAw1s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Th3p-0USy973"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rUJVP_tbCO_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# "
      ],
      "metadata": {
        "id": "T3QA2oqgCQKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from math import ceil\n",
        "\n",
        "\n",
        "base_model= [\n",
        "\n",
        "    #expand_ratio , channels ,repeats , stride , kernel_size     \n",
        "    [1, 16 ,1 ,1 ,3],\n",
        "    [6, 24 ,2 ,2 ,3],\n",
        "    [6, 40 ,2 ,2 ,5],\n",
        "    [6, 80 ,3 ,2 ,3],\n",
        "    [6, 112 ,3 ,1, 5],         \n",
        "    [6, 192 ,4 ,2, 5],\n",
        "    [6, 320 ,1 ,1 ,3],\n",
        "             \n",
        "]\n",
        "\n",
        "\n",
        "phi_values = {\n",
        "    \n",
        "    \"b0\":(0,224,0.2),\n",
        "    \"b1\":(0.5,240,0.2),\n",
        "    \"b2\":(1,260,0.3),\n",
        "    \"b3\":(2,300,0.3),\n",
        "    \"b4\":(3,380,0.4),\n",
        "    \"b5\":(4,456,0.4),\n",
        "    \"b6\":(5,528,0.5),\n",
        "    \"b7\":(6,600,0.5),\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "ZkWw3Q9HCiCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNNBlock"
      ],
      "metadata": {
        "id": "l83h2zqbSzxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from math import ceil\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CNNBlock(nn.Module):\n",
        "  def __init__(\n",
        "      self,in_channels, out_channels ,kernel_size,stride ,padding,groups=1 ):\n",
        "    \n",
        "    super(CNNBlock, self).__init__()\n",
        "    self.cnn = nn.Conv2d(\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        padding,\n",
        "        groups=groups,\n",
        "    )\n",
        "    self.bn = nn.BatchNorm2d(out_channels)\n",
        "    self.silu= nn.SiLU() #SiLU <-> Swish\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.silu(self.bn(self.cnn(x)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "ZW7xRDKYWXhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SqueezeExcitation"
      ],
      "metadata": {
        "id": "7zrmLgl1S3MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SqueezeExcitation(nn.Module):\n",
        "  def __init__(self,in_channels, reduced_dim):\n",
        "    super(SqueezeExcitation, self).__init__()\n",
        "    self.se =nn.Sequential(\n",
        "     nn.AdaptiveAvgPool2d(1), \n",
        "     nn.Conv2d(in_channels, reduced_dim, 1),\n",
        "     nn.SiLU(),\n",
        "     nn.Conv2d(reduced_dim,in_channels, 1),\n",
        "     nn.Sigmoid(),\n",
        "    )   \n",
        "  def forward(self, x):\n",
        "     return x*self.se(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "NS2Ut2ctZ21K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# InvertedResidualBlock"
      ],
      "metadata": {
        "id": "4UfJKftXTPMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InvertedResidualBlock(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      in_channels,\n",
        "      out_channels,\n",
        "      kernel_size,\n",
        "      stride,\n",
        "      padding,\n",
        "      expand_ratio,\n",
        "      reduction=4,\n",
        "      survival_prob=0.8,\n",
        "\n",
        "  ):\n",
        "    super(InvertedResidualBlock, self).__init__()\n",
        "    self.survival_prob = 0.8\n",
        "    self.use_residual = in_channels == out_channels and stride == 1 \n",
        "    hidden_dim  = in_channels * expand_ratio\n",
        "    self.expand = in_channels != hidden_dim\n",
        "    reduced_dim = int(in_channels / reduction)\n",
        "\n",
        "    if self.expand:\n",
        "      self.expand_conv = CNNBlock(in_channels,hidden_dim,kernel_size=3,stride=1,padding=1,\n",
        "      )\n",
        "    \n",
        "    self.conv = nn.Sequential(\n",
        "      CNNBlock(\n",
        "          hidden_dim, hidden_dim, kernel_size,stride,padding, groups=hidden_dim,\n",
        "      ),\n",
        "      SqueezeExcitation(hidden_dim, reduced_dim),\n",
        "      nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "    )\n",
        "\n",
        "  def stochastic_depth(self, x):\n",
        "     if not self.training:\n",
        "       return x\n",
        "     binary_tensor = torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.survival_prob\n",
        "     return torch.div(x, self.survival_prob)*binary_tensor\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, inputs):\n",
        "     x= self.expand_conv(inputs) if self.expand else inputs \n",
        "\n",
        "     if self.use_residual:\n",
        "       return self.stochastic_depth(self.conv(x)) + inputs\n",
        "     else:\n",
        "       return self.conv(x)"
      ],
      "metadata": {
        "id": "7YyrPEreeNAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Uw-JGeSMTfFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Efficient Net"
      ],
      "metadata": {
        "id": "k1XFCqjxmCDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNet(nn.Module):\n",
        "  def __init__(self, version, num_classes):\n",
        "    super(EfficientNet,self).__init__()\n",
        "    width_factor, depth_factor, dropout_rate=self.calculate_factors(version)\n",
        "    last_channels = ceil(1280*width_factor)\n",
        "    self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.features = self.create_features(width_factor, depth_factor, last_channels)\n",
        "    self.classifier= nn.Sequential(\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(last_channels, num_classes),\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "  def calculate_factors(self,version,alpha=1.2, beta=1.1):\n",
        "    phi , res ,drop_rate = phi_values[version]\n",
        "    depth_factor = alpha**phi\n",
        "    width_factor = beta**phi\n",
        "    return width_factor,depth_factor, drop_rate \n",
        "\n",
        "  def create_features(self,width_factor,depth_factor,last_channels):\n",
        "    channels =int(32*width_factor)\n",
        "    features =[CNNBlock(3,channels, 3, stride=2,padding=1)]\n",
        "    in_channels = channels \n",
        "\n",
        "    for expand_ratio, channels, repeats , stride , kernel_size in base_model:\n",
        "      out_channels = 4*ceil(int(channels*width_factor)/4)\n",
        "      layers_repeats=  ceil(repeats * depth_factor)\n",
        "\n",
        "      for layer in range(layers_repeats):\n",
        "        features.append(\n",
        "            InvertedResidualBlock(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                expand_ratio=expand_ratio,\n",
        "                stride = stride if layer == 0 else 1,\n",
        "                kernel_size=kernel_size,\n",
        "                padding=kernel_size//2,\n",
        "            )\n",
        "            \n",
        "        )\n",
        "        in_channels = out_channels\n",
        "\n",
        "      features.append(\n",
        "        CNNBlock(in_channels, last_channels, kernel_size=1 , stride=1, padding=0)\n",
        "      )\n",
        "\n",
        "      return nn.Sequential(*features)\n",
        "\n",
        "  def forward(self,x):\n",
        "     x = self.pool(self.features(x))\n",
        "     return self.classifier(x.view(x.shape[0], -1))\n",
        "  \n",
        "        \n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "EdrgpwPdUc19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaulation &  comparision\n"
      ],
      "metadata": {
        "id": "Ctn7fTqwP6_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "version =\"b0\"\n",
        "num_examples, num_classes = 4, 10\n",
        "\n",
        "net=EfficientNet(version=version,num_classes=num_classes)\n",
        "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device)"
      ],
      "metadata": {
        "id": "jW6D5eCPQLLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)"
      ],
      "metadata": {
        "id": "peald5KdQNGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    \n",
        "    running_loss= 0.0\n",
        "    for i ,data in enumerate(trainloader, 0):\n",
        "        \n",
        "        inputs, labels =data\n",
        "        device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        inputs, labels =inputs.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs=net(inputs)\n",
        "        loss =criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 ==1999:\n",
        "            print(f'[{epoch+1},{i+1:5d}] loss: {running_loss / 2000 :.3f}')\n",
        "            running_loss =0.0\n",
        "            \n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "PDJRGZNKQOxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PATH ='./clfar_net.pth'\n",
        "torch.save(net.state_dict(),PATH)"
      ],
      "metadata": {
        "id": "EFSB8-8bQQ3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net =Net()\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "outputs = net(images)\n",
        "\n",
        "\n",
        "\n",
        "dataiter =iter(testloader)\n",
        "images , labels =dataiter.next()\n",
        "\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ' ,''.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "id": "ZBfQEbMiQSeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred =  {classname: 0 for classname in classes}"
      ],
      "metadata": {
        "id": "vpYNoA1UQUw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predictions =torch.max(outputs, 1)\n",
        "\n",
        "    for label, prediction in zip(labels, predictions):\n",
        "      if label ==prediction:\n",
        "        correct_pred[classes[label]] += 1\n",
        "      total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "\n",
        "for classname, correct_count in correct_pred.items():\n",
        "  accuracy =100*float(correct_count) / total_pred[classname]\n",
        "  print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "id": "wFCFUPbBQWVL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}