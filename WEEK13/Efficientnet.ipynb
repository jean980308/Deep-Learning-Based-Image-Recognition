{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Efficientnet.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CFAR-10"
      ],
      "metadata": {
        "id": "BrBdsOJgi07v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lqOrj5nRI7P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset     = torchvision.datasets.CIFAR10(root='./data' ,train=True,download=True,transform=transform)\n",
        "\n",
        "trainloader   = torch.utils.data.DataLoader(trainset , batch_size=batch_size,shuffle=True , num_workers=2)\n",
        "\n",
        "testset     = torchvision.datasets.CIFAR10(root='./data' ,train=True,download=True , transform=transform)\n",
        "\n",
        "testloader =torch.utils.data.DataLoader(testset , batch_size=batch_size ,shuffle=False ,num_workers=2)\n",
        "\n",
        "classes = ('plane' , 'car' ,'bird' , 'cat' , 'deer' ,'dog' ,'frog' ,'horse' ,'ship' , 'truck')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PDEO_mJ1SGZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    img= img/2 +0.5\n",
        "    npimg=img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "    plt.show()\n",
        "    \n",
        "dataiter= iter(trainloader)\n",
        "images , labels =dataiter.next()\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "print(''.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "Ccr3nfgGSG5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    img= img/2 +0.5\n",
        "    npimg=img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "    plt.show()\n",
        "    \n",
        "dataiter= iter(trainloader)\n",
        "images , labels =dataiter.next()\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "print(''.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "28rqzj_1THXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 剛開始設定的初始值\n"
      ],
      "metadata": {
        "id": "R_fRASeUTO1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from math import ceil\n",
        "\n",
        "\n",
        "base_model= [\n",
        "\n",
        "    #expand_ratio , channels ,repeats , stride , kernel_size     \n",
        "    [1, 16 ,1 ,1 ,3],\n",
        "    [6, 24 ,2 ,2 ,3],\n",
        "    [6, 40 ,2 ,2 ,5],\n",
        "    [6, 80 ,3 ,2 ,3],\n",
        "    [6, 112 ,3 ,1, 5],         \n",
        "    [6, 192 ,4 ,2, 5],\n",
        "    [6, 320 ,1 ,1 ,3],\n",
        "             \n",
        "]\n",
        "\n",
        "\n",
        "phi_values = {\n",
        "    \n",
        "    \"b0\":(0,224,0.2),\n",
        "    \"b1\":(0.5,240,0.2),\n",
        "    \"b2\":(1,260,0.3),\n",
        "    \"b3\":(2,300,0.3),\n",
        "    \"b4\":(3,380,0.4),\n",
        "    \"b5\":(4,456,0.4),\n",
        "    \"b6\":(5,528,0.5),\n",
        "    \"b7\":(6,600,0.5),\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "g3Bx42e_TX9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNNBlock"
      ],
      "metadata": {
        "id": "fDs90xSDTcgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from math import ceil\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CNNBlock(nn.Module):\n",
        "  def __init__(\n",
        "      self,in_channels, out_channels ,kernel_size,stride ,padding,groups=1 ):\n",
        "    \n",
        "    super(CNNBlock, self).__init__()\n",
        "    self.cnn = nn.Conv2d(\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size,\n",
        "        stride,\n",
        "        padding,\n",
        "        groups=groups,\n",
        "    )\n",
        "    self.bn = nn.BatchNorm2d(out_channels)\n",
        "    self.silu= nn.SiLU() #SiLU <-> Swish\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.silu(self.bn(self.cnn(x)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "9FB4pY2PTfrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SqueezeExcitation"
      ],
      "metadata": {
        "id": "j8c6AakKTnsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SqueezeExcitation(nn.Module):\n",
        "  def __init__(self,in_channels, reduced_dim):\n",
        "    super(SqueezeExcitation, self).__init__()\n",
        "    self.se =nn.Sequential(\n",
        "     nn.AdaptiveAvgPool2d(1), \n",
        "     nn.Conv2d(in_channels, reduced_dim, 1),\n",
        "     nn.SiLU(),\n",
        "     nn.Conv2d(reduced_dim,in_channels, 1),\n",
        "     nn.Sigmoid(),\n",
        "    )   \n",
        "  def forward(self, x):\n",
        "     return x*self.se(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "5XrN3MmUTsHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# InvertedResidualBlock"
      ],
      "metadata": {
        "id": "zZR7rsVQTvFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InvertedResidualBlock(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      in_channels,\n",
        "      out_channels,\n",
        "      kernel_size,\n",
        "      stride,\n",
        "      padding,\n",
        "      expand_ratio,\n",
        "      reduction=4,\n",
        "      survival_prob=0.8,\n",
        "\n",
        "  ):\n",
        "    super(InvertedResidualBlock, self).__init__()\n",
        "    self.survival_prob = 0.8\n",
        "    self.use_residual = in_channels == out_channels and stride == 1 \n",
        "    hidden_dim  = in_channels * expand_ratio\n",
        "    self.expand = in_channels != hidden_dim\n",
        "    reduced_dim = int(in_channels / reduction)\n",
        "\n",
        "    if self.expand:\n",
        "      self.expand_conv = CNNBlock(in_channels,hidden_dim,kernel_size=3,stride=1,padding=1,\n",
        "      )\n",
        "    \n",
        "    self.conv = nn.Sequential(\n",
        "      CNNBlock(\n",
        "          hidden_dim, hidden_dim, kernel_size,stride,padding, groups=hidden_dim,\n",
        "      ),\n",
        "      SqueezeExcitation(hidden_dim, reduced_dim),\n",
        "      nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "    )\n",
        "\n",
        "  def stochastic_depth(self, x):\n",
        "     if not self.training:\n",
        "       return x\n",
        "     binary_tensor = torch.rand(x.shape[0], 1, 1, 1, device=x.device) < self.survival_prob\n",
        "     return torch.div(x, self.survival_prob)*binary_tensor\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, inputs):\n",
        "     x= self.expand_conv(inputs) if self.expand else inputs \n",
        "\n",
        "     if self.use_residual:\n",
        "       return self.stochastic_depth(self.conv(x)) + inputs\n",
        "     else:\n",
        "       return self.conv(x)"
      ],
      "metadata": {
        "id": "M7lKyEcaT2ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Efficient Net"
      ],
      "metadata": {
        "id": "kBKpkWpAVYXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNet(nn.Module):\n",
        "  def __init__(self, version, num_classes):\n",
        "    super(EfficientNet,self).__init__()\n",
        "    width_factor, depth_factor, dropout_rate=self.calculate_factors(version)\n",
        "    last_channels = ceil(1280*width_factor)\n",
        "    self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.features = self.create_features(width_factor, depth_factor, last_channels)\n",
        "    self.classifier= nn.Sequential(\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(last_channels, num_classes),\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "  def calculate_factors(self,version,alpha=1.2, beta=1.1):\n",
        "    phi , res ,drop_rate = phi_values[version]\n",
        "    depth_factor = alpha**phi\n",
        "    width_factor = beta**phi\n",
        "    return width_factor,depth_factor, drop_rate \n",
        "\n",
        "  def create_features(self,width_factor,depth_factor,last_channels):\n",
        "    channels =int(32*width_factor)\n",
        "    features =[CNNBlock(3,channels, 3, stride=2,padding=1)]\n",
        "    in_channels = channels \n",
        "\n",
        "    for expand_ratio, channels, repeats , stride , kernel_size in base_model:\n",
        "      out_channels = 4*ceil(int(channels*width_factor)/4)\n",
        "      layers_repeats=  ceil(repeats * depth_factor)\n",
        "\n",
        "      for layer in range(layers_repeats):\n",
        "        features.append(\n",
        "            InvertedResidualBlock(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                expand_ratio=expand_ratio,\n",
        "                stride = stride if layer == 0 else 1,\n",
        "                kernel_size=kernel_size,\n",
        "                padding=kernel_size//2,\n",
        "            )\n",
        "            \n",
        "        )\n",
        "        in_channels = out_channels\n",
        "\n",
        "      features.append(\n",
        "        CNNBlock(in_channels, last_channels, kernel_size=1 , stride=1, padding=0)\n",
        "      )\n",
        "\n",
        "      return nn.Sequential(*features)\n",
        "\n",
        "  def forward(self,x):\n",
        "     x = self.pool(self.features(x))\n",
        "     return self.classifier(x.view(x.shape[0], -1))\n",
        "  \n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "7-o28CeZVcbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Evaulation &  comparision"
      ],
      "metadata": {
        "id": "CETW9A0vT_61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "version =\"b0\"\n",
        "num_examples, num_classes = 4, 10\n",
        "\n",
        "net=EfficientNet(version=version,num_classes=num_classes)\n",
        "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device)"
      ],
      "metadata": {
        "id": "SXAeUdj8UILG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)"
      ],
      "metadata": {
        "id": "ykrPMlhAUWFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for epoch in range(100):\n",
        "    \n",
        "    running_loss= 0.0\n",
        "    for i ,data in enumerate(trainloader, 0):\n",
        "        \n",
        "        inputs, labels =data\n",
        "        device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        inputs, labels =inputs.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs=net(inputs)\n",
        "        loss =criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 ==1999:\n",
        "            print(f'[{epoch+1},{i+1:5d}] loss: {running_loss / 2000 :.3f}')\n",
        "            running_loss =0.0\n",
        "            \n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "XVMCh_EzUbcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PATH ='./clfar_net.pth'\n",
        "torch.save(net.state_dict(),PATH)"
      ],
      "metadata": {
        "id": "fv7PXTA_UiJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "version =\"b0\"\n",
        "num_examples, num_classes = 4, 10\n",
        "net =EfficientNet(version=version,num_classes=num_classes)\n",
        "\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "outputs = net(images)\n",
        "\n",
        "\n",
        "\n",
        "dataiter =iter(testloader)\n",
        "images , labels =dataiter.next()\n",
        "\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ' ,''.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "id": "7u5Dwpk4Ujv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred =  {classname: 0 for classname in classes}"
      ],
      "metadata": {
        "id": "i3ZZlm9pUmR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predictions =torch.max(outputs, 1)\n",
        "\n",
        "    for label, prediction in zip(labels, predictions):\n",
        "      if label ==prediction:\n",
        "        correct_pred[classes[label]] += 1\n",
        "      total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "\n",
        "for classname, correct_count in correct_pred.items():\n",
        "  accuracy =100*float(correct_count) / total_pred[classname]\n",
        "  print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "id": "AJJMHCKoUn28"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}